{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11037605,"sourceType":"datasetVersion","datasetId":6874910}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport json\nimport numpy as np\nimport re\nimport string\nimport nltk\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n","metadata":{"id":"BbaaB3gRQYC-","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:27.630163Z","iopub.execute_input":"2025-03-15T16:46:27.630500Z","iopub.status.idle":"2025-03-15T16:46:32.172263Z","shell.execute_reply.started":"2025-03-15T16:46:27.630464Z","shell.execute_reply":"2025-03-15T16:46:32.171622Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# The 'punkt' resource is a pre-trained model used for tokenization, which is the process of splitting text into individual words or sentences.\n# The 'tab' part likely refers to a variant or extension of the punkt tokenizer that may handle tab-separated data or related formatting nuances.\n# Downloading this resource ensures that the tokenizer is available for use in subsequent NLP tasks.\nnltk.download('punkt_tab')","metadata":{"id":"5G8d1LwtzVJ4","outputId":"ae14cc98-7d70-4544-b64a-6e5ca943e3dd","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:33.332081Z","iopub.execute_input":"2025-03-15T16:46:33.332691Z","iopub.status.idle":"2025-03-15T16:46:33.676810Z","shell.execute_reply.started":"2025-03-15T16:46:33.332653Z","shell.execute_reply":"2025-03-15T16:46:33.675957Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"with open('/kaggle/input/ee958-cap-test/train_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n    data = json.load(file)","metadata":{"id":"7AlwK-6j60v8","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:35.864535Z","iopub.execute_input":"2025-03-15T16:46:35.864851Z","iopub.status.idle":"2025-03-15T16:46:36.992440Z","shell.execute_reply.started":"2025-03-15T16:46:35.864826Z","shell.execute_reply":"2025-03-15T16:46:36.991723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# initialize the variables to process JSON data\nsource_sentences_train = []\ntarget_sentences_train = []\n\nsource_sentences_val = []\ntarget_sentences_val = []\n\nid_train = []\nid_val = []","metadata":{"id":"wMIkjevT60zr","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:38.285880Z","iopub.execute_input":"2025-03-15T16:46:38.286148Z","iopub.status.idle":"2025-03-15T16:46:38.290065Z","shell.execute_reply.started":"2025-03-15T16:46:38.286129Z","shell.execute_reply":"2025-03-15T16:46:38.289226Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Display the list of Language pairs\nfor language_pair, language_data in data.items():\n  print(f\"Language Pair: {language_pair}\")\n","metadata":{"id":"T8qZLgFq95HO","outputId":"e314bbe2-aa9f-458c-b254-457e0fe70536","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:40.741913Z","iopub.execute_input":"2025-03-15T16:46:40.742203Z","iopub.status.idle":"2025-03-15T16:46:40.746720Z","shell.execute_reply.started":"2025-03-15T16:46:40.742181Z","shell.execute_reply":"2025-03-15T16:46:40.745975Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Bengali\nLanguage Pair: English-Hindi\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load souce and target for Training\nfor language_pair, language_data in data.items():\n    if(language_pair == \"English-Bengali\"):\n      print(f\"Language Pair: {language_pair}\")\n      for data_type, data_entries in language_data.items():\n          print(f\"  Data Type: {data_type}\")\n          for entry_id, entry_data in data_entries.items():\n              source = entry_data[\"source\"]\n              target = entry_data[\"target\"]\n              if (data_type == \"Validation\"):\n                source_sentences_val.append(source)\n                target_sentences_val.append(target)\n                id_val.append(entry_id)\n              else:\n                source_sentences_train.append(source)\n                target_sentences_train.append(target)\n                id_train.append(entry_id)","metadata":{"id":"MXWfKbhq606u","outputId":"6145e945-fa9b-48f2-a442-19979ca16a54","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:43.191784Z","iopub.execute_input":"2025-03-15T16:46:43.192055Z","iopub.status.idle":"2025-03-15T16:46:43.232027Z","shell.execute_reply.started":"2025-03-15T16:46:43.192036Z","shell.execute_reply":"2025-03-15T16:46:43.231365Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Bengali\n  Data Type: Train\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"with open('/kaggle/input/ee958-cap-test/val_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n    data = json.load(file)","metadata":{"id":"3D-V5lgY60-u","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:45.832318Z","iopub.execute_input":"2025-03-15T16:46:45.832607Z","iopub.status.idle":"2025-03-15T16:46:45.914255Z","shell.execute_reply.started":"2025-03-15T16:46:45.832586Z","shell.execute_reply":"2025-03-15T16:46:45.913612Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load souce and target for Validation\nfor language_pair, language_data in data.items():\n    if(language_pair == \"English-Bengali\"):\n      print(f\"Language Pair: {language_pair}\")\n      for data_type, data_entries in language_data.items():\n          print(f\"  Data Type: {data_type}\")\n          for entry_id, entry_data in data_entries.items():\n              source = entry_data[\"source\"]\n              #target = entry_data[\"target\"]\n              if (data_type == \"Validation\"):\n                source_sentences_val.append(source)\n                #target_sentences_val.append(target)\n                #id_val.append(entry_id)\n              #else:\n                #source_sentences_train.append(source)\n                #target_sentences_train.append(target)\n                #id_train.append(entry_id)","metadata":{"id":"eW1JJK4x61HG","outputId":"d020623c-f554-4ac1-dcef-3663c2cf0429","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:47.442910Z","iopub.execute_input":"2025-03-15T16:46:47.443201Z","iopub.status.idle":"2025-03-15T16:46:47.486579Z","shell.execute_reply.started":"2025-03-15T16:46:47.443180Z","shell.execute_reply":"2025-03-15T16:46:47.485788Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Bengali\n  Data Type: Validation\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(len(source_sentences_train))\nprint(len(target_sentences_train))\n\nprint(len(source_sentences_val))\nprint(len(target_sentences_val))","metadata":{"id":"2TXJ4t-K4niH","outputId":"a8bfcfa7-c11b-42d5-c922-7b5be8ea766f","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:50.331123Z","iopub.execute_input":"2025-03-15T16:46:50.331426Z","iopub.status.idle":"2025-03-15T16:46:50.336790Z","shell.execute_reply.started":"2025-03-15T16:46:50.331405Z","shell.execute_reply":"2025-03-15T16:46:50.335943Z"}},"outputs":[{"name":"stdout","text":"68849\n68849\n9836\n0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"x={'English':source_sentences_train,'Bengali':target_sentences_train}","metadata":{"id":"lkWlRlRG4prO","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:52.506460Z","iopub.execute_input":"2025-03-15T16:46:52.506742Z","iopub.status.idle":"2025-03-15T16:46:52.510322Z","shell.execute_reply.started":"2025-03-15T16:46:52.506722Z","shell.execute_reply":"2025-03-15T16:46:52.509454Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df=pd.DataFrame(x)","metadata":{"id":"etynR9dz4puy","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:54.915410Z","iopub.execute_input":"2025-03-15T16:46:54.915683Z","iopub.status.idle":"2025-03-15T16:46:54.942272Z","shell.execute_reply.started":"2025-03-15T16:46:54.915665Z","shell.execute_reply":"2025-03-15T16:46:54.941468Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df","metadata":{"id":"frGC33Ob4p2I","outputId":"77dc9a79-9e57-4e1f-cc41-08eca3982b3b","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:46:57.499679Z","iopub.execute_input":"2025-03-15T16:46:57.499985Z","iopub.status.idle":"2025-03-15T16:46:57.527544Z","shell.execute_reply.started":"2025-03-15T16:46:57.499964Z","shell.execute_reply":"2025-03-15T16:46:57.526873Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                 English  \\\n0      Do not forget to visit the point where the Nar...   \n1      It is evident that the biggest cause of povert...   \n2      The film was released theatrically on 12 April...   \n3                 is wyatt's birthday party at ten p. m.   \n4      Apart from being used as an eatable, barley is...   \n...                                                  ...   \n68844  But it is evident that there is change in both...   \n68845  Include a detailed listing of all of your prod...   \n68846  Each subcategory counts as one page, pages in ...   \n68847  It is one of the country's oldest state-run pu...   \n68848  It will also put an end to the unnecessary use...   \n\n                                                 Bengali  \n0      এই জায়গাগুলো দেখতে ভুলো না যেখানে নর্মদা নদী ম...  \n1       এই কথা স্পষ্ট যে দরিদ্রতার বড় কারণ হল অশিক্ষা ।  \n2      চলচ্চিত্রটি ২০১৩ সালের ১২ই এপ্রিল প্রেক্ষাগৃহে...  \n3                  অনিমেষ এর জন্মদিনের পার্টি রাত দশটায়  \n4      খাদ্যদ্রব্য ছাড়াও যব আরো বিভিন্ন ক্ষেত্রে যেমন...  \n...                                                  ...  \n68844  তাও এটা প্রত্যক্ষভাবে দেখা যায় যে প্রিন্ট মিড...  \n68845  ছবি সহ সম্পূর্ণ করা আপনার সমস্ত পণ্যের একটি বি...  \n68846  প্রতিটি উপবিভাগ একটি পৃষ্ঠা হিসাবে গণনা করা হয...  \n68847  এটি দেশের সবচেয়ে পুরনো রাষ্ট্র-চালিত সরকারী বা...  \n68848  সাথেই সারের অনাবশ্যক প্রয়োগের উপরও লাগাম টানা ...  \n\n[68849 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Bengali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Do not forget to visit the point where the Nar...</td>\n      <td>এই জায়গাগুলো দেখতে ভুলো না যেখানে নর্মদা নদী ম...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It is evident that the biggest cause of povert...</td>\n      <td>এই কথা স্পষ্ট যে দরিদ্রতার বড় কারণ হল অশিক্ষা ।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The film was released theatrically on 12 April...</td>\n      <td>চলচ্চিত্রটি ২০১৩ সালের ১২ই এপ্রিল প্রেক্ষাগৃহে...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is wyatt's birthday party at ten p. m.</td>\n      <td>অনিমেষ এর জন্মদিনের পার্টি রাত দশটায়</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Apart from being used as an eatable, barley is...</td>\n      <td>খাদ্যদ্রব্য ছাড়াও যব আরো বিভিন্ন ক্ষেত্রে যেমন...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68844</th>\n      <td>But it is evident that there is change in both...</td>\n      <td>তাও এটা প্রত্যক্ষভাবে দেখা যায় যে প্রিন্ট মিড...</td>\n    </tr>\n    <tr>\n      <th>68845</th>\n      <td>Include a detailed listing of all of your prod...</td>\n      <td>ছবি সহ সম্পূর্ণ করা আপনার সমস্ত পণ্যের একটি বি...</td>\n    </tr>\n    <tr>\n      <th>68846</th>\n      <td>Each subcategory counts as one page, pages in ...</td>\n      <td>প্রতিটি উপবিভাগ একটি পৃষ্ঠা হিসাবে গণনা করা হয...</td>\n    </tr>\n    <tr>\n      <th>68847</th>\n      <td>It is one of the country's oldest state-run pu...</td>\n      <td>এটি দেশের সবচেয়ে পুরনো রাষ্ট্র-চালিত সরকারী বা...</td>\n    </tr>\n    <tr>\n      <th>68848</th>\n      <td>It will also put an end to the unnecessary use...</td>\n      <td>সাথেই সারের অনাবশ্যক প্রয়োগের উপরও লাগাম টানা ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>68849 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import nltk\nfrom collections import Counter","metadata":{"id":"3XRxnK3y4p6V","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:00.315491Z","iopub.execute_input":"2025-03-15T16:47:00.315779Z","iopub.status.idle":"2025-03-15T16:47:00.319087Z","shell.execute_reply.started":"2025-03-15T16:47:00.315759Z","shell.execute_reply":"2025-03-15T16:47:00.318294Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Function to preprocess and remove punctuation and numbers\ndef preprocess_and_remove_punctuation(sentence):\n    # Remove punctuation and numbers\n    sentence = ''.join([char for char in sentence if char not in string.punctuation and not char.isdigit()])\n    return sentence","metadata":{"id":"K9OBOZcH4p9Q","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:02.234587Z","iopub.execute_input":"2025-03-15T16:47:02.234886Z","iopub.status.idle":"2025-03-15T16:47:02.238727Z","shell.execute_reply.started":"2025-03-15T16:47:02.234861Z","shell.execute_reply":"2025-03-15T16:47:02.238088Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Tokenization and Lowercasing\ndef preprocess(sentences):\n    tokenized_sentences = [nltk.word_tokenize(preprocess_and_remove_punctuation(sentence.lower())) for sentence in sentences]\n    return tokenized_sentences","metadata":{"id":"TIZLuTIH4qCD","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:04.050371Z","iopub.execute_input":"2025-03-15T16:47:04.050658Z","iopub.status.idle":"2025-03-15T16:47:04.054688Z","shell.execute_reply.started":"2025-03-15T16:47:04.050636Z","shell.execute_reply":"2025-03-15T16:47:04.053817Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"target_sentences_train = [re.sub(r'[a-zA-Z]','',hi) for hi in target_sentences_train] #optional","metadata":{"id":"bKfE17bs4qI8","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:06.256703Z","iopub.execute_input":"2025-03-15T16:47:06.257107Z","iopub.status.idle":"2025-03-15T16:47:06.401389Z","shell.execute_reply.started":"2025-03-15T16:47:06.257074Z","shell.execute_reply":"2025-03-15T16:47:06.400550Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"english_tokens = preprocess(source_sentences_train)\nenglish_test=preprocess(source_sentences_val)\nhindi_tokens = preprocess(target_sentences_train)\nhindi_test=preprocess(target_sentences_val)","metadata":{"id":"Vlge8LLR4qKn","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:07.993983Z","iopub.execute_input":"2025-03-15T16:47:07.994262Z","iopub.status.idle":"2025-03-15T16:47:26.334504Z","shell.execute_reply.started":"2025-03-15T16:47:07.994242Z","shell.execute_reply":"2025-03-15T16:47:26.333856Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"en_train=english_tokens\nen_test=english_test\nde_train=hindi_tokens\nde_test=hindi_test","metadata":{"id":"deSMTBa-5maR","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:28.538470Z","iopub.execute_input":"2025-03-15T16:47:28.538747Z","iopub.status.idle":"2025-03-15T16:47:28.542566Z","shell.execute_reply.started":"2025-03-15T16:47:28.538727Z","shell.execute_reply":"2025-03-15T16:47:28.541794Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\nde_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n\nfor ds in [en_train, en_test]:\n    for sent in ds:\n        for token in sent:\n            if token not in en_index2word:\n                en_index2word.append(token)\n\nfor ds in [de_train, de_test]:\n    for sent in ds:\n        for token in sent:\n            if token not in de_index2word:\n                de_index2word.append(token)","metadata":{"id":"hhPcNh2L4qPT","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:47:31.238147Z","iopub.execute_input":"2025-03-15T16:47:31.238466Z","iopub.status.idle":"2025-03-15T16:51:36.895711Z","shell.execute_reply.started":"2025-03-15T16:47:31.238440Z","shell.execute_reply":"2025-03-15T16:51:36.894720Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"en_index2word","metadata":{"id":"vKBqf2kl9id2","outputId":"bd368e5c-f3e1-4cd8-b5c2-355cdc9e6042","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:51:40.147489Z","iopub.execute_input":"2025-03-15T16:51:40.147808Z","iopub.status.idle":"2025-03-15T16:51:40.162550Z","shell.execute_reply.started":"2025-03-15T16:51:40.147781Z","shell.execute_reply":"2025-03-15T16:51:40.161550Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['<PAD>',\n '<SOS>',\n '<EOS>',\n 'do',\n 'not',\n 'forget',\n 'to',\n 'visit',\n 'the',\n 'point',\n 'where',\n 'narmada',\n 'flowing',\n 'through',\n 'marble',\n 'rocks',\n 'interchanges',\n 'its',\n 'calmness',\n 'and',\n 'serenity',\n 'into',\n 'insouciance',\n 'it',\n 'is',\n 'evident',\n 'that',\n 'biggest',\n 'cause',\n 'of',\n 'poverty',\n 'illiteracy',\n 'film',\n 'was',\n 'released',\n 'theatrically',\n 'on',\n 'april',\n 'wyatts',\n 'birthday',\n 'party',\n 'at',\n 'ten',\n 'p',\n 'm',\n 'apart',\n 'from',\n 'being',\n 'used',\n 'as',\n 'an',\n 'eatable',\n 'barley',\n 'also',\n 'in',\n 'many',\n 'other',\n 'fields',\n 'like',\n 'industries',\n 'agriculture',\n 'emperor',\n 'akbar',\n 'got',\n 'state',\n 'museum',\n 'constructed',\n 'during',\n 'his',\n 'trip',\n 'ajmer',\n 'initiate',\n 'music',\n 'electronic',\n 'playlist',\n 'srinagar',\n 'a',\n 'distance',\n 'kms',\n 'jammu',\n 'devotee',\n 'chosen',\n 'karaga',\n 'or',\n 'clay',\n 'pot',\n 'placed',\n 'head',\n 'city',\n 'lined',\n 'up',\n 'with',\n 'shops',\n 'have',\n 'everything',\n 'you',\n 'need',\n 'stock',\n 'your',\n 'kitchen',\n 'shelves',\n 'we',\n 'can',\n 'express',\n 'our',\n 'feelings',\n 'unwind',\n 'ourselves',\n 'different',\n 'ways',\n 'share',\n 'those',\n 'whom',\n 'know',\n 'trust',\n 'common',\n 'picnic',\n 'spot',\n 'by',\n 'locals',\n 'best',\n 'way',\n 'protect',\n 'newly',\n 'born',\n 'infant',\n 'infection',\n 'lift',\n 'after',\n 'cleaning',\n 'ones',\n 'hand',\n 'soap',\n 'beforehand',\n 'various',\n 'categories',\n 'persons',\n 'having',\n 'risk',\n 'behaviours',\n 'who',\n 'report',\n 'nicd',\n 'for',\n 'hiv',\n 'testing',\n 'are',\n 'given',\n 'pretest',\n 'post',\n 'test',\n 'continuum',\n 'counseling',\n 'per',\n 'individual',\n 'case',\n 'merit',\n 'varanasi',\n 'bombings',\n 'were',\n 'series',\n 'occurred',\n 'across',\n 'hindu',\n 'holy',\n 'march',\n 'one',\n 'legends',\n 'relating',\n 'eklingji',\n 'killing',\n 'vrakshasurindra',\n 'had',\n 'meditated',\n 'prayed',\n 'penitence',\n 'get',\n 'rid',\n 'curse',\n 'good',\n 'food',\n 'this',\n 'thought',\n 'be',\n 'very',\n 'profitable',\n 'all',\n 'important',\n 'entertaining',\n 'areas',\n 'among',\n 'dead',\n 'black',\n 'kettle',\n 'wife',\n 'massacre',\n 'remembered',\n 'battle',\n 'washita',\n 'commemorated',\n 'battlefield',\n 'national',\n 'historic',\n 'site',\n 'there',\n 'old',\n 'palace',\n 'shiva',\n 'temple',\n 'nadaun',\n 'let',\n 'me',\n 'about',\n 'current',\n 'traffic',\n 'carmen',\n 'drive',\n 'country',\n '’',\n 's',\n 'top',\n 'places',\n 'eat',\n 'nestled',\n 'remote',\n 'rural',\n 'countryside',\n 'even',\n 'tiniest',\n 'villages',\n 'boast',\n 'gourmet',\n 'farmers',\n 'markets',\n 'here',\n 'see',\n 'processing',\n 'world',\n 'famous',\n 'darjeeling',\n 'tea',\n 'belongs',\n 'hinayana',\n 'buddhism',\n 'sect',\n 'maharashtra',\n 'reading',\n 'bright',\n 'light',\n 'night',\n 'working',\n 'excessively',\n 'dangerous',\n 'eyes',\n 'silk',\n 'weft',\n 'designs',\n 'borders',\n 'whereas',\n 'cotton',\n 'body',\n 'fabric',\n 'some',\n 'men',\n 'may',\n 'experience',\n 'urinary',\n 'frequency',\n 'urgency',\n 'incontinence',\n 'but',\n 'will',\n 'settle',\n 'third',\n 'month',\n 'surgery',\n 'change',\n 'radio',\n 'station',\n 'products',\n 'techniques',\n 'exhibited',\n 'total',\n 'stalls',\n 'along',\n 'big',\n 'fair',\n 'agricultural',\n 'industry',\n 'exhibition',\n 'most',\n 'them',\n 'dietary',\n 'origin',\n 'every',\n 'year',\n 'shravana',\n 'julyaugust',\n 'when',\n 'moon',\n 'full',\n 'thousands',\n 'devout',\n 'pilgrims',\n 'gather',\n 'before',\n 'amarnath',\n 'cave',\n 'picturesque',\n 'lidder',\n 'valley',\n 'kashmir',\n 'offer',\n 'their',\n 'prayers',\n 'lord',\n 'lost',\n 'people',\n 'calling',\n 'friends',\n 'language',\n 'same',\n 'name',\n 'yatuman',\n 'awesta',\n 'than',\n 'occurrence',\n 'cramps',\n 'certain',\n 'nerve',\n 'fiber',\n 'located',\n 'lower',\n 'part',\n 'back',\n 'initial',\n 'years',\n 'fruit',\n 'production',\n 'less',\n 'later',\n 'productivity',\n 'increases',\n 'gradually',\n 'described',\n 'indian',\n 'classical',\n 'poet',\n 'tagore',\n 'tear',\n 'face',\n 'eternity',\n 'taj',\n 'mahal',\n 'undoubtedly',\n 'zenith',\n 'moghal',\n 'architecture',\n 'quite',\n 'simply',\n 'worlds',\n 'marvelous',\n 'buildings',\n 'therefore',\n 'hilly',\n 'india',\n 'started',\n 'strawberry',\n 'cultivation',\n 'park',\n 'features',\n 'marine',\n 'natural',\n 'study',\n 'center',\n 'tel',\n 'tourist',\n 'service',\n 'please',\n 'set',\n 'reminder',\n 'my',\n 'calendar',\n 'meeting',\n 'twenty',\n 'five',\n 'crosssectional',\n 'data',\n 'analyzed',\n 'children',\n 'andhra',\n 'pradesh',\n 'vietnam',\n 'sampled',\n 'within',\n 'sites',\n 'each',\n 'then',\n 'communities',\n 'suddenly',\n 'shivaji',\n 'tore',\n 'stomach',\n 'baghnakha',\n 'walk',\n 'green',\n 'lawns',\n 'tomb',\n 'towards',\n 'akshardam',\n 'claims',\n 'bastion',\n 'hinduism',\n 'irrelevant',\n 'say',\n 'bharat',\n 'muni',\n 'mentioned',\n 'samavakaar',\n 'ihamrig',\n 'dim',\n 'vyayog',\n 'utsrishtikak',\n 'etc',\n 'type',\n 'plays',\n 'natyashashtra',\n 'beer',\n 'bar',\n 'drink',\n 'any',\n 'brussels',\n 'i',\n 'want',\n 'something',\n 'order',\n 'recognized',\n 'government',\n 'kerala',\n 'sports',\n 'council',\n 'institute',\n 'training',\n 'weaponry',\n 'art',\n 'called',\n 'kalariyapattu',\n 'new',\n 'zealand',\n 'kiwi',\n 'day',\n 'king',\n 'expressed',\n 'dissatisfaction',\n 'she',\n 'prepared',\n 'because',\n 'marvellous',\n 'craft',\n 'treasure',\n 'cracow',\n 'polish',\n 'rome',\n 'buy',\n 'beautiful',\n 'handicrafts',\n 'taste',\n 'mouthwatering',\n 'return',\n 'trove',\n 'pleasant',\n 'memories',\n 'modern',\n 'times',\n 'tarana',\n 'commonly',\n 'associated',\n 'singer',\n 'amir',\n 'khan',\n 'helped',\n 'popularize',\n 'researched',\n 'origins',\n 'syllables',\n 'true',\n 'extent',\n 'vectors',\n 'still',\n 'unknown',\n 'iron',\n 'synthesis',\n 'color',\n 'chlorophyll',\n 'maintenance',\n 'goans',\n 'would',\n 'tourists',\n 'stay',\n 'house',\n 'assist',\n 'levels',\n 'starting',\n 'subsidy',\n 'pepper',\n 'form',\n 'main',\n 'ingredient',\n 'kadhi',\n 'powder',\n 'chaat',\n 'masala',\n 'pulao',\n 'chana',\n 'meat',\n 'sambhar',\n 'eastern',\n 'direction',\n 'red',\n 'fort',\n 'filth',\n 'filled',\n 'colony',\n 'chor',\n 'bazar',\n 'open',\n 'urinals',\n 'obstacled',\n 'sewers',\n 'disease',\n 'filaria',\n 'spreads',\n 'bite',\n 'mosquitoes',\n 'named',\n 'culecs',\n 'pipians',\n 'both',\n 'these',\n 'prevent',\n 'nutritional',\n 'anemia',\n 'what',\n 'time',\n 'york',\n 'amblyopia',\n 'uncommon',\n 'present',\n 'rarely',\n 'dense',\n 'cancel',\n 'tomorrow',\n 'cut',\n 'down',\n 'sugar',\n 'completely',\n 'if',\n 'clear',\n 'diabetic',\n 'feathers',\n 'impart',\n 'substantial',\n 'drag',\n 'causing',\n 'shuttlecock',\n 'decelerate',\n 'greatly',\n 'over',\n 'how',\n 'much',\n 'money',\n 'left',\n 'freecharge',\n 'wallet',\n 'symptom',\n 'heart',\n 'becomes',\n 'weak',\n 'too',\n 'hard',\n 'work',\n 'weakness',\n 'participating',\n 'maha',\n 'shivratri',\n 'festival',\n 'unique',\n 'according',\n 'historical',\n 'records',\n 'built',\n 'sometime',\n 'th',\n 'century',\n 'ruins',\n 'ancient',\n 'patliputra',\n 'inside',\n 'patna',\n 'seen',\n 'today',\n 'rafi',\n 'stated',\n 'he',\n 'only',\n 'so',\n 'keen',\n 'sing',\n 'lata',\n 'him',\n 'bangladesh',\n 'has',\n 'traced',\n 'relationship',\n 'between',\n 'death',\n 'degrees',\n 'wasting',\n 'stunting',\n 'wickets',\n 'second',\n 'innings',\n 'took',\n 'maiden',\n 'wicket',\n 'haul',\n 'firstclass',\n 'cricket',\n 'feat',\n 'achieve',\n 'twice',\n 'cashier',\n 'scan',\n 'code',\n 'rajputs',\n 'reciprocate',\n 'arrange',\n 'padmini',\n 'sit',\n 'room',\n 'edge',\n 'water',\n 'tank',\n 'confluence',\n 'sutlej',\n 'river',\n 'harike',\n 'barrage',\n 'divert',\n 'combined',\n 'flows',\n 'rivers',\n 'irrigation',\n 'canals',\n 'serve',\n 'rajasthan',\n 'punjab',\n 'due',\n 'tension',\n 'beginning',\n 'january',\n 'import',\n 'onion',\n 'which',\n 'imported',\n 'pakistan',\n 'via',\n 'waghaatari',\n 'affected',\n 'formation',\n 'belly',\n 'tested',\n 'tapping',\n 'method',\n 'finger',\n 'feels',\n 'pressure',\n 'popular',\n 'climbing',\n 'example',\n 'united',\n 'states',\n 'australia',\n 'sacred',\n 'indigenous',\n 'peoples',\n 'hotels',\n 'auli',\n 'wherein',\n 'book',\n 'rooms',\n 'solution',\n 'tolerate',\n 'contact',\n 'lenses',\n 'nausea',\n 'starts',\n 'occurring',\n 'culture',\n 'rajasthani',\n 'village',\n 'jaipur',\n 'no',\n 'better',\n 'place',\n 'chokhi',\n 'dhani',\n 'martial',\n 'arts',\n 'systems',\n 'devolved',\n 'they',\n 'became',\n 'forms',\n 'storytelling',\n 'entertainment',\n 'shows',\n 'sport',\n 'gauda',\n 'jagor',\n 'impression',\n 'social',\n 'life',\n 'displays',\n 'existing',\n 'moods',\n 'modes',\n 'human',\n 'characters',\n 'reason',\n 'area',\n 'idols',\n 'related',\n 'vaishnav',\n 'shaiv',\n 'buddhist',\n 'religion',\n 'found',\n 'baijnath',\n 'dwadash',\n 'jyotirlingas',\n 'indeed',\n 'cinema',\n 'television',\n 'images',\n 'chain',\n 'pasture',\n 'grass',\n 'seeds',\n 'small',\n 'sowing',\n 'requires',\n 'care',\n 'attention',\n 'detail',\n 'few',\n 'days',\n 'establishment',\n 'crucial',\n 'miles',\n 'ahead',\n 'chatti',\n 'right',\n 'side',\n 'waterfalls',\n 'caves',\n 'little',\n 'field',\n 'haatchatti',\n 'pipalkoti',\n 'personal',\n 'emails',\n 'come',\n 'yet',\n 'vitamin',\n 'e',\n 'more',\n 'amount',\n 'sleeps',\n 'well',\n 'barely',\n 'hear',\n 'olly',\n 'race',\n 'earned',\n 'crore',\n 'rupees',\n 'validated',\n 'algorithms',\n 'visually',\n 'appealing',\n 'graphics',\n 'treatment',\n 'decisions',\n 'chefs',\n 'matthew',\n 'special',\n 'lunch',\n 'value',\n 'conscious',\n 'priced',\n 'rs',\n 'nearest',\n 'rail',\n 'reach',\n 'hemis',\n 'high',\n 'altitude',\n 'kilometres',\n 'fruits',\n 'decomposed',\n 'international',\n 'ecotourism',\n 'society',\n 'defines',\n 'responsible',\n 'travel',\n 'conserves',\n 'environment',\n 'improves',\n 'wellbeing',\n 'local',\n 'lights',\n 'blue',\n 'long',\n 'period',\n 'tensions',\n 'father',\n 'halfbrother',\n 'khurram',\n 'began',\n 'drift',\n 'closer',\n 'considered',\n 'de',\n 'facto',\n 'heirapparent',\n 'court',\n 'chroniclers',\n 'temples',\n 'triratha',\n 'nagara',\n 'style',\n 'bangalore',\n 'monsoon',\n 'stays',\n 'june',\n 'september',\n 'uttar',\n 'celebrated',\n 'malaria',\n 'mass',\n 'awareness',\n 'did',\n 'speak',\n 'often',\n 'irregular',\n 'menstrual',\n 'complaints',\n 'hair',\n 'nails',\n 'skin',\n 'appear',\n 'women',\n 'miraculously',\n 'denizens',\n 'virile',\n 'land',\n 'always',\n 'resurrected',\n 'rebuilt',\n 'lives',\n 'confident',\n 'optimistic',\n 'ban',\n 'gus',\n 'han',\n 'tells',\n 'us',\n 'kushans',\n 'divided',\n 'bactria',\n 'bc',\n 'prominent',\n 'joy',\n 'merriment',\n 'find',\n 'price',\n 'view',\n 'doctors',\n 'dieticians',\n 'alone',\n 'medicine',\n 'sunset',\n 'thirty',\n 'design',\n 'motifs',\n 'brocades',\n 'intricate',\n 'floral',\n 'foliage',\n 'patterns',\n 'kalga',\n 'bel',\n 'string',\n 'upright',\n 'leaves',\n 'jhalar',\n 'decorate',\n 'sari',\n 'pallas',\n 'dupattas',\n 'whats',\n 'next',\n 'list',\n 'although',\n 'chhatrasal',\n 'repeatedly',\n 'sought',\n 'baji',\n 'raos',\n 'assistance',\n 'busy',\n 'malwa',\n 'create',\n 'email',\n 'writings',\n 'chess',\n 'theory',\n 'cultural',\n 'variety',\n 'large',\n 'number',\n 'cultivars',\n 'bandy',\n 'sweden',\n '–',\n 'playing',\n 'spectator',\n 'great',\n 'fortitude',\n 'dedication',\n 'twitter',\n 'send',\n 'message',\n 'seizures',\n 'types',\n 'symptoms',\n 'occur',\n 'together',\n 'separately',\n 'song',\n 'background',\n 'play',\n 'downloaded',\n 'blood',\n 'person',\n 'infected',\n 'hepatitis',\n 'b',\n 'virus',\n 'alive',\n 'celia',\n 'lottridge',\n 'katherine',\n 'grier',\n 'storytellers',\n 'educators',\n 'taught',\n 'program',\n 'joan',\n 'godhum',\n 'sym',\n 'punjika',\n 'piles',\n 'put',\n 'grains',\n 'wheat',\n 'paisa',\n 'hide',\n 'spread',\n 'tends',\n 'epidemics',\n 'outbreaks',\n 'himalayas',\n 'adorned',\n 'valleys',\n 'enough',\n 'slopes',\n 'exploited',\n 'positively',\n 'sake',\n 'adventure',\n 'louder',\n 'maximum',\n 'planetarium',\n 'anshi',\n 'spanning',\n 'square',\n 'north',\n ...]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Save vocabularies for English-Hindi\nwith open('/kaggle/working/bn_en_index2word.json', 'w') as f:\n    json.dump(en_index2word, f)\nwith open('/kaggle/working/bn_de_index2word.json', 'w') as f:\n    json.dump(de_index2word, f)\nprint(\"English-Hindi vocabularies saved to bn_en_index2word.json and bn_de_index2word.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:51:50.946992Z","iopub.execute_input":"2025-03-15T16:51:50.947265Z","iopub.status.idle":"2025-03-15T16:51:51.027718Z","shell.execute_reply.started":"2025-03-15T16:51:50.947245Z","shell.execute_reply":"2025-03-15T16:51:51.027026Z"}},"outputs":[{"name":"stdout","text":"English-Hindi vocabularies saved to bn_en_index2word.json and bn_de_index2word.json\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# torch.cuda.is_available() checks if a CUDA-enabled GPU is available.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"op5h3x5a7lKz","outputId":"3455f8af-d6dc-46bc-b6a0-d5274ddf8e9d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# It iterates through the en_index2word list using enumerate(), which provides both the index (idx) and the value (token, which is a word).\n# For each word, it creates a key-value pair in the dictionary, where the key is the word (token) and the value is its index (idx).\nen_word2index = {token: idx for idx, token in enumerate(en_index2word)}\nde_word2index = {token: idx for idx, token in enumerate(de_index2word)}","metadata":{"id":"YCD8R66I7lMs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(en_word2index)","metadata":{"id":"3NAVQ4Wc4qTd","outputId":"7a1936eb-4b00-49e9-e1a2-03076dade37e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#it divides the total length by the number of sentences (len(en_train)) to get the average sentence length.\nen_lengths = sum([len(sent) for sent in en_train])/len(en_train)\nde_lengths = sum([len(sent) for sent in de_train])/len(de_train)","metadata":{"id":"VhU217lr4njs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_length = 20","metadata":{"id":"bUmeVoIn61Kx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_and_pad(vocab, sent, max_length):\n    \"\"\"\n    Encodes a sentence using a vocabulary and pads or truncates it to a specified maximum length.\n\n    Args:\n        vocab (dict): A dictionary mapping words to their corresponding indices.\n        sent (list): A list of words representing the sentence to be encoded.\n        max_length (int): The maximum length of the encoded and padded/truncated sentence.\n\n    Returns:\n        list: The encoded and padded/truncated sentence as a list of indices.\n    \"\"\"\n\n    # Define special tokens: Start of Sentence (SOS), End of Sentence (EOS), and Padding (PAD).\n    sos = [vocab[\"<SOS>\"]]\n    eos = [vocab[\"<EOS>\"]]\n    pad = [vocab[\"<PAD>\"]]\n\n    # Check if the sentence length (excluding SOS and EOS) is less than the maximum length.\n    if len(sent) < max_length - 2: # -2 for SOS and EOS\n        # Calculate the number of padding tokens needed.\n        n_pads = max_length - 2 - len(sent)\n        # Encode the sentence by looking up the index of each word in the vocabulary.\n        encoded = [vocab[w] for w in sent]\n        return sos + encoded + eos + pad * n_pads\n    else: # sent is longer than max_length; truncating\n        encoded = [vocab[w] for w in sent]\n        truncated = encoded[:max_length - 2]\n        return sos + truncated + eos","metadata":{"id":"hKpPwrsb61Of","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encoded Training data\nen_train_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_train]\nen_test_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_test]\nde_train_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_train]\nde_test_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_test]","metadata":{"id":"zOVE8NxB61SJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"en_train_encoded[1]","metadata":{"id":"HQeTtXSK-G3p","outputId":"449aa297-94b7-4e08-cee2-edbd0fffc6e3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 256\n\ntrain_x = np.array(en_train_encoded)\ntrain_y = np.array(de_train_encoded)\ntest_x = np.array(en_test_encoded)\ntest_y = np.array(de_test_encoded)\n\ntrain_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\ntest_ds = TensorDataset(torch.from_numpy(test_x))\n\n\n#train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\ntrain_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=2) #added pin_memory and num_workers\n#test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)","metadata":{"id":"zIC407YH9Eif","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_x[1]","metadata":{"id":"zWzPn5U3-iX2","outputId":"59e4264a-cf3e-4aca-872e-a668fff665f4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds[1]","metadata":{"id":"IpdQcKeB-siQ","outputId":"bf3af5a6-6f3e-4eb1-d861-25f254460d42","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math","metadata":{"id":"IxcBu2_S8HsY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"Ayb64QDK91uR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# As suggested in online docs we need to use a positional encoder for Transformaers\n\nclass PositionalEncoding(nn.Module):\n    \"\"\"\n    This module implements positional encoding for transformer models.\n    Written with help of:\n    https://www.geeksforgeeks.org/positional-encoding-in-transformers/\n    https://github.com/hyunwoongko/transformer\n\n    Positional encoding adds information about the position of tokens in a sequence to the input embeddings.\n    This is crucial because transformer models, unlike recurrent neural networks, do not inherently\n    process sequential data in order.\n    \"\"\"\n    def __init__(self, d_model, max_len=5000):\n        \"\"\"\n        Initializes the PositionalEncoding module.\n\n        Args:\n            d_model (int): The dimensionality of the input embeddings.\n            max_len (int): The maximum length of the sequences the model can handle.\n        \"\"\"\n        # Create a zero tensor of shape (max_len, d_model) to store the positional encodings.\n        super(PositionalEncoding, self).__init__()\n        # Create a zero tensor of shape (max_len, d_model) to store the positional encodings.\n        pe = torch.zeros(max_len, d_model)\n        # Create a tensor of positions from 0 to max_len-1.\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        # Calculate the division term for the sinusoidal functions.\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        # Calculate the sine and cosine values for even indices and odd indices.\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        # Add a batch dimension to the positional encoding tensor. WHY????? TODO figure out\n        pe = pe.unsqueeze(0)\n        # Buffers are tensors that  are not updated during trainin but are still\n        # saved in the model's state dictionary.\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        Applies positional encoding to the input tensor.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, sequence_length, d_model).\n\n        Returns:\n            torch.Tensor: The input tensor with positional encoding added, of the same shape as x.\n        \"\"\"\n        # The positional encoding is sliced to match the sequence length of the input.\n        return x + self.pe[:, :x.size(1), :]\n","metadata":{"id":"nrjcbW8T4JEY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Improved Encoder and Decoder with LSTM and Attention\nclass EnhancedEncoder(nn.Module):\n    \"\"\"\n    An enhanced encoder module that combines embedding, positional encoding, multi-head attention,\n    and feed-forward network for sequence encoding.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_heads=4, dropout=0.1):\n        \"\"\"\n        Initializes the EnhancedEncoder module.\n\n        Args:\n            input_size (int): The size of the input vocabulary.\n            hidden_size (int): The dimensionality of the hidden state and embeddings.\n            num_heads (int): The number of attention heads.\n            dropout (float): Dropout probability.\n        \"\"\"\n        super(EnhancedEncoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n\n        # Embedding layer to convert input tokens to embeddings.\n        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n        # Positional encoding to add positional information to embeddings.\n        self.pos_encoding = PositionalEncoding(hidden_size)\n        # Multi-head attention layer.\n        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Layer normalization after attention.\n        self.norm1 = nn.LayerNorm(hidden_size)\n        # Layer normalization after feed-forward network.\n        self.norm2 = nn.LayerNorm(hidden_size)\n        # Feed-forward network.\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size * 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size * 4, hidden_size)\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, hidden=None):\n        \"\"\"\n        Forward pass of the encoder.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (batch_size, seq_length).\n            hidden (torch.Tensor, optional): Hidden state (not used in this encoder).\n\n        Returns:\n            tuple: A tuple containing the encoder output and None (for compatibility).\n        \"\"\"\n        # Embed the input tokens. \n        embedded = self.embedding(input)  # [batch_size, seq_length, hidden_size]\n        # Add positional encoding. need to figure out why this is a must\n        embedded = self.pos_encoding(embedded)\n        # Permute dimensions for multi-head attention. \n        # https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853\n        embedded = embedded.permute(1, 0, 2)  # [seq_length, batch_size, hidden_size]\n\n        # Apply multi-head attention.\n        # https://paperswithcode.com/method/multi-head-attention\n        attn_output, _ = self.attention(embedded, embedded, embedded)\n        attn_output = self.norm1(embedded + self.dropout(attn_output))\n        ffn_output = self.ffn(attn_output)\n        output = self.norm2(attn_output + self.dropout(ffn_output))\n        output = output.permute(1, 0, 2)  # [batch_size, seq_length, hidden_size]\n        return output, None\n\n    def initHidden(self):\n        \"\"\"\n        Initializes the hidden state (not used in this encoder).\n\n        Returns:\n            None\n        \"\"\"\n        return None","metadata":{"id":"1hNA9u659U-E","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EnhancedDecoder(nn.Module):\n    \"\"\"\n    An enhanced decoder module that combines embedding, positional encoding, self-attention,\n    encoder-decoder attention, and a feed-forward network for sequence decoding.\n    \"\"\"\n    def __init__(self, hidden_size, output_size, num_heads=4, dropout=0.1):\n        \"\"\"\n        Initializes the EnhancedDecoder module.\n\n        Args:\n            hidden_size (int): The dimensionality of the hidden state and embeddings.\n            output_size (int): The size of the output vocabulary.\n            num_heads (int): The number of attention heads.\n            dropout (float): Dropout probability.\n        \"\"\"\n        super(EnhancedDecoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n\n        # Embedding layer to convert input tokens to embeddings.\n        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n        # Positional encoding to add positional information to embeddings.\n        self.pos_encoding = PositionalEncoding(hidden_size)\n        # Self-attention layer.\n        self.self_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Encoder-decoder attention layer.\n        self.enc_dec_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Layer normalization after self-attention.\n        self.norm1 = nn.LayerNorm(hidden_size)\n        # Layer normalization after encoder-decoder attention.\n        self.norm2 = nn.LayerNorm(hidden_size)\n        # Layer normalization after feed-forward network.\n        self.norm3 = nn.LayerNorm(hidden_size)\n        # Feed-forward network.\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size * 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size * 4, hidden_size)\n        )\n        # Output linear layer.\n        self.out = nn.Linear(hidden_size, output_size)\n        # Log softmax for output probabilities.\n        self.softmax = nn.LogSoftmax(dim=-1)\n        # Dropout layer.\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, encoder_output, mask=None):\n        \"\"\"\n        Forward pass of the decoder.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n            encoder_output (torch.Tensor): Output tensor from the encoder of shape (batch_size, src_seq_len, hidden_size).\n            mask (torch.Tensor, optional): Mask for self-attention (e.g., for padding or look-ahead).\n\n        Returns:\n            tuple: A tuple containing the decoder output and None (for compatibility).\n        \"\"\"\n        # Embed the input tokens.\n        embedded = self.embedding(input)  # [batch_size, seq_len, hidden_size]\n        # Add positional encoding.\n        embedded = self.pos_encoding(embedded)\n        # Permute dimensions for multi-head attention.\n        embedded = embedded.permute(1, 0, 2)  # [seq_len, batch_size, hidden_size]\n        # Permute encoder output dimensions for encoder-decoder attention.\n        enc_output = encoder_output.permute(1, 0, 2)  # [src_seq_len, batch_size, hidden_size]\n\n        # Apply self-attention.\n        self_attn_output, _ = self.self_attention(embedded, embedded, embedded, attn_mask=mask)\n        # Apply layer normalization and residual connection after self-attention.\n        self_attn_output = self.norm1(embedded + self.dropout(self_attn_output))\n\n        # Apply encoder-decoder attention.\n        attn_output, _ = self.enc_dec_attention(self_attn_output, enc_output, enc_output)\n        # Apply layer normalization and residual connection after encoder-decoder attention.\n        attn_output = self.norm2(self_attn_output + self.dropout(attn_output))\n\n        # Apply feed-forward network.\n        ffn_output = self.ffn(attn_output)\n        # Apply layer normalization and residual connection after feed-forward network.\n        output = self.norm3(attn_output + self.dropout(ffn_output))\n        # Permute dimensions back to (batch_size, seq_len, hidden_size).\n        output = output.permute(1, 0, 2)  # [batch_size, seq_len, hidden_size]\n\n        # Output logits for the last token only\n        output = self.out(output[:, -1, :])  # [batch_size, output_size]\n        output = self.softmax(output)\n        return output, None\n\n    # We do not need an .initHidden() method for the decoder since the encoder output will act as input in the first decoder time-step","metadata":{"id":"d050fwM09Xad","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modified instantiation\nhidden_size = 128  # Increased hidden size for better representation\nencoder = EnhancedEncoder(len(en_index2word), hidden_size).to(device)\ndecoder = EnhancedDecoder(hidden_size, len(de_index2word)).to(device)\n\n#criterion = nn.CrossEntropyLoss(ignore_index=0)\n#enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n#dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n\n# Training loop\ncriterion = nn.CrossEntropyLoss()\nenc_optimizer = torch.optim.Adam(encoder.parameters(), lr=3e-3)\ndec_optimizer = torch.optim.Adam(decoder.parameters(), lr=3e-3)\n\nlosses = []\n\n\n#EPOCHS\n\nepochs = 50  # Increased epochs since transformer-style models often need more training\nSOS = en_word2index[\"<SOS>\"]\nEOS = en_word2index[\"<EOS>\"]","metadata":{"id":"9KKwV9qS9Eyw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    \"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf')\"\"\"\n    # Create an upper triangular matrix of ones.\n    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n    # Replace 0s with float('-inf') and 1s with 0.0.\n    # masked_fill(condition, value) replaces elements where the condition is true with the specified value.\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask","metadata":{"id":"5IH25tA04lYz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_epoch(encoder, decoder, train_dl, criterion, enc_optimizer, dec_optimizer):\n    \"\"\"\n    Trains the encoder and decoder models for one epoch.\n\n    Args:\n        encoder (nn.Module): The encoder model.\n        decoder (nn.Module): The decoder model.\n        train_dl (DataLoader): DataLoader for the training dataset.\n        criterion (nn.Module): Loss function.\n        enc_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n        dec_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n\n    Returns:\n        float: Average loss for the epoch.\n    \"\"\"\n    # Set the models to training mode.\n    encoder.train()\n    decoder.train()\n    total_loss = 0\n\n    # Iterate over batches in the training DataLoader.\n    for idx, batch in enumerate(train_dl):\n        # Move input and target tensors to the device.\n        input_tensor = batch[0].to(device)  # [batch_size, seq_length]\n        target_tensor = batch[1].to(device)  # [batch_size, seq_length]\n\n        # Zero the gradients of the optimizers.\n        enc_optimizer.zero_grad()\n        dec_optimizer.zero_grad()\n\n        # Enable gradient calculation.\n        with torch.set_grad_enabled(True):\n            # Encode the input sequence.\n            encoder_output, _ = encoder(input_tensor)\n\n            # Initialize decoder input with SOS token.\n            batch_size = input_tensor.size(0)\n            decoder_input = torch.full((batch_size, 1), SOS, dtype=torch.long).to(device)\n            # Generate the mask for the decoder.\n            mask = generate_square_subsequent_mask(seq_length).to(device)\n            # Initialize a tensor to store the decoder results.\n            dec_result = torch.zeros(batch_size, seq_length, len(de_index2word)).to(device)\n\n            # Iterate over the target sequence length.\n            for t in range(1, seq_length):\n                # Decode the input sequence up to time step t\n                decoder_output, _ = decoder(\n                    decoder_input[:, :t],\n                    encoder_output,\n                    mask[:t, :t]\n                )\n                # Assign the 2D output directly\n                dec_result[:, t] = decoder_output  # [batch_size, vocab_size]\n\n                # Prepare the next decoder input.\n                if t < seq_length - 1:\n                    decoder_input = torch.cat(\n                        [decoder_input, target_tensor[:, t].unsqueeze(1)],\n                        dim=1\n                    )\n\n            # Reshape the decoder results and target tensor for loss calculation.\n            scores = dec_result[:, 1:].reshape(-1, len(de_index2word))\n            targets = target_tensor[:, 1:].reshape(-1)\n            loss = criterion(scores, targets)\n\n            # Backpropagate the loss and update the model parameters.\n            loss.backward()\n            # Clip gradients to prevent exploding gradients. Smoothing the learning process\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n            enc_optimizer.step()\n            dec_optimizer.step()\n\n            total_loss += loss.item()\n\n            if idx % 10 == 0:\n                avg_loss = total_loss / (idx + 1)\n                print(f\"Batch {idx}, Loss: {avg_loss:.4f}\")\n\n    # Average loss for this epoch\n    return total_loss / len(train_dl)","metadata":{"id":"PaZA3ZXr-YNL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full training loop\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n    avg_loss = train_epoch(encoder, decoder, train_dl, criterion, enc_optimizer, dec_optimizer)\n    losses.append(avg_loss)\n    print(f\"Average Loss: {avg_loss:.4f}\")","metadata":{"id":"KlQHK9zb468x","outputId":"52f752f8-f399-4ec3-b7c8-357f24093d14","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot losses\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Over Time')\nplt.show()","metadata":{"id":"xuyYw5C29E6Q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save models for English-Bengali\ntorch.save(encoder.state_dict(), '/kaggle/working/encoder_bn.pth')\ntorch.save(decoder.state_dict(), '/kaggle/working/decoder_bn.pth')\nprint(\"English-Bengali Encoder and Decoder saved\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modified evaluation code\n# Evaluation\n# Corrected Evaluation\ndef evaluate(encoder, decoder, test_ds):\n    \"\"\"\n    Evaluates the encoder and decoder models on the test dataset.\n\n    Args:\n        encoder (nn.Module): The encoder model.\n        decoder (nn.Module): The decoder model.\n        test_ds (Dataset): The test dataset.\n\n    Returns:\n        list: A list of predicted sentences as strings.\n    \"\"\"\n    # Set the models to evaluation mode.\n    encoder.eval()\n    decoder.eval()\n    val_outs = []\n\n    # Disable gradient calculation during evaluation.\n    with torch.no_grad():\n        # Iterate over the test dataset.\n        for i in tqdm(range(len(test_ds))):\n            # Get the input tensor and move it to the device.\n            input_tensor = test_ds[i][0].unsqueeze(0).to(device)\n            encoder_output, _ = encoder(input_tensor)\n            # Initialize the decoder input with the SOS token.\n            decoder_input = torch.tensor([[SOS]], device=device)  # [1, 1]\n            result = []\n\n            # Iterate over the sequence length.\n            for t in range(seq_length):\n                # Generate the mask for the decoder.\n                mask = generate_square_subsequent_mask(t + 1).to(device)\n                # Decode the input sequence up to time step t.\n                decoder_output, _ = decoder(decoder_input, encoder_output, mask)\n                # Get the predicted token index.\n                best = decoder_output.argmax(-1)  # [batch_size], here [1]\n                pred_token = best.item()\n                \n                result.append(de_index2word[pred_token])\n\n                # Check if the predicted token is the EOS token.\n                if pred_token == EOS:\n                    break\n                    \n                \n                # Prepare the next decoder input.\n                # Ensure 2D tensor by concatenating with a tensor containing the pred_token.\n                # Fix: by unsqueezing only once\n                decoder_input = torch.cat(\n                    [decoder_input, torch.tensor([[pred_token]], device=device)],\n                    dim=1\n                )\n\n            # Remove special tokens from the result list.\n            result = [token for token in result if token not in ['<EOS>', '<PAD>', '<SOS>']]\n            # Construct sentence\n            val_outs.append(\" \".join(result))\n    \n    return val_outs","metadata":{"id":"pZBPRQqM5Pfz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nencoder = EnhancedEncoder(len(en_index2word), hidden_size).to(device)\ndecoder = EnhancedDecoder(hidden_size, len(de_index2word)).to(device)\n\n\n#encoder.load_state_dict(torch.load('/kaggle/working/encoder_hi.pth'))\n#decoder.load_state_dict(torch.load('/kaggle/working/decoder_hi.pth'))\n\n# Load saved state dictionaries with weights_only=True\nencoder.load_state_dict(torch.load('/kaggle/working/encoder_bn.pth', weights_only=True))\ndecoder.load_state_dict(torch.load('/kaggle/working/decoder_bn.pth', weights_only=True))\nprint(\"English-Bengali Encoder and Decoder loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run evaluation\nval_ids = [i for i, _ in data[\"English-Bengali\"][\"Validation\"].items()]\nval_outs = evaluate(encoder, decoder, test_ds)","metadata":{"id":"keeFGS8L5RgB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save results\ndf0 = pd.DataFrame()\ndf0[\"ID\"] = val_ids\ndf0[\"Translation\"] = val_outs\n#df0.to_csv('/kaggle/working/answersH.csv', index=False)\ndf0.to_csv('/kaggle/working/answersB.csv', index=False)","metadata":{"id":"83naaUJdGthF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=pd.read_csv(\"/kaggle/working/answersB.csv\")","metadata":{"id":"0YPeBfJDGtmL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x","metadata":{"id":"A2S8UnGoLKDt","trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11037686,"sourceType":"datasetVersion","datasetId":6874973}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport json\nimport numpy as np\nimport re\nimport string\nimport nltk\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n","metadata":{"id":"BbaaB3gRQYC-","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:58:50.319744Z","iopub.execute_input":"2025-03-15T15:58:50.320020Z","iopub.status.idle":"2025-03-15T15:58:50.324880Z","shell.execute_reply.started":"2025-03-15T15:58:50.319991Z","shell.execute_reply":"2025-03-15T15:58:50.323957Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n# The 'punkt' resource is a pre-trained model used for tokenization, which is the process of splitting text into individual words or sentences.\n# The 'tab' part likely refers to a variant or extension of the punkt tokenizer that may handle tab-separated data or related formatting nuances.\n# Downloading this resource ensures that the tokenizer is available for use in subsequent NLP tasks.\nnltk.download('punkt_tab')","metadata":{"id":"5G8d1LwtzVJ4","outputId":"ae14cc98-7d70-4544-b64a-6e5ca943e3dd","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:58:53.525584Z","iopub.execute_input":"2025-03-15T15:58:53.525904Z","iopub.status.idle":"2025-03-15T15:58:53.808744Z","shell.execute_reply.started":"2025-03-15T15:58:53.525878Z","shell.execute_reply":"2025-03-15T15:58:53.807997Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"with open('/kaggle/input/ee958-cap-train/train_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n    data = json.load(file)","metadata":{"id":"7AlwK-6j60v8","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:58:56.204367Z","iopub.execute_input":"2025-03-15T15:58:56.204640Z","iopub.status.idle":"2025-03-15T15:58:57.397639Z","shell.execute_reply.started":"2025-03-15T15:58:56.204620Z","shell.execute_reply":"2025-03-15T15:58:57.396744Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# initialize the variables to process JSON data\nsource_sentences_train = []\ntarget_sentences_train = []\n\nsource_sentences_val = []\ntarget_sentences_val = []\n\nid_train = []\nid_val = []","metadata":{"id":"wMIkjevT60zr","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:58:58.525197Z","iopub.execute_input":"2025-03-15T15:58:58.525507Z","iopub.status.idle":"2025-03-15T15:58:58.529264Z","shell.execute_reply.started":"2025-03-15T15:58:58.525481Z","shell.execute_reply":"2025-03-15T15:58:58.528485Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Display the list of Language pairs\nfor language_pair, language_data in data.items():\n  print(f\"Language Pair: {language_pair}\")\n","metadata":{"id":"T8qZLgFq95HO","outputId":"e314bbe2-aa9f-458c-b254-457e0fe70536","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:00.986134Z","iopub.execute_input":"2025-03-15T15:59:00.986420Z","iopub.status.idle":"2025-03-15T15:59:00.990847Z","shell.execute_reply.started":"2025-03-15T15:59:00.986399Z","shell.execute_reply":"2025-03-15T15:59:00.989964Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Bengali\nLanguage Pair: English-Hindi\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load souce and target for Training\nfor language_pair, language_data in data.items():\n    if(language_pair == \"English-Hindi\"):\n      print(f\"Language Pair: {language_pair}\")\n      for data_type, data_entries in language_data.items():\n          print(f\"  Data Type: {data_type}\")\n          for entry_id, entry_data in data_entries.items():\n              source = entry_data[\"source\"]\n              target = entry_data[\"target\"]\n              if (data_type == \"Validation\"):\n                source_sentences_val.append(source)\n                target_sentences_val.append(target)\n                id_val.append(entry_id)\n              else:\n                source_sentences_train.append(source)\n                target_sentences_train.append(target)\n                id_train.append(entry_id)","metadata":{"id":"MXWfKbhq606u","outputId":"6145e945-fa9b-48f2-a442-19979ca16a54","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:02.958218Z","iopub.execute_input":"2025-03-15T15:59:02.958498Z","iopub.status.idle":"2025-03-15T15:59:03.006076Z","shell.execute_reply.started":"2025-03-15T15:59:02.958476Z","shell.execute_reply":"2025-03-15T15:59:03.005412Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Hindi\n  Data Type: Train\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"with open('/kaggle/input/ee958-cap-train/val_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n    data = json.load(file)","metadata":{"id":"3D-V5lgY60-u","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:05.735123Z","iopub.execute_input":"2025-03-15T15:59:05.735409Z","iopub.status.idle":"2025-03-15T15:59:05.832131Z","shell.execute_reply.started":"2025-03-15T15:59:05.735386Z","shell.execute_reply":"2025-03-15T15:59:05.831481Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load souce and target for Validation\nfor language_pair, language_data in data.items():\n    if(language_pair == \"English-Hindi\"):\n      print(f\"Language Pair: {language_pair}\")\n      for data_type, data_entries in language_data.items():\n          print(f\"  Data Type: {data_type}\")\n          for entry_id, entry_data in data_entries.items():\n              source = entry_data[\"source\"]\n              #target = entry_data[\"target\"]\n              if (data_type == \"Validation\"):\n                source_sentences_val.append(source)\n                #target_sentences_val.append(target)\n                #id_val.append(entry_id)\n              #else:\n                #source_sentences_train.append(source)\n                #target_sentences_train.append(target)\n                #id_train.append(entry_id)","metadata":{"id":"eW1JJK4x61HG","outputId":"d020623c-f554-4ac1-dcef-3663c2cf0429","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:08.142008Z","iopub.execute_input":"2025-03-15T15:59:08.142279Z","iopub.status.idle":"2025-03-15T15:59:08.159464Z","shell.execute_reply.started":"2025-03-15T15:59:08.142259Z","shell.execute_reply":"2025-03-15T15:59:08.158401Z"}},"outputs":[{"name":"stdout","text":"Language Pair: English-Hindi\n  Data Type: Validation\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(len(source_sentences_train))\nprint(len(target_sentences_train))\n\nprint(len(source_sentences_val))\nprint(len(target_sentences_val))","metadata":{"id":"2TXJ4t-K4niH","outputId":"a8bfcfa7-c11b-42d5-c922-7b5be8ea766f","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:10.720907Z","iopub.execute_input":"2025-03-15T15:59:10.721200Z","iopub.status.idle":"2025-03-15T15:59:10.726433Z","shell.execute_reply.started":"2025-03-15T15:59:10.721175Z","shell.execute_reply":"2025-03-15T15:59:10.725589Z"}},"outputs":[{"name":"stdout","text":"80797\n80797\n11543\n0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"x={'English':source_sentences_train,'Hindi':target_sentences_train}","metadata":{"id":"lkWlRlRG4prO","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:13.208877Z","iopub.execute_input":"2025-03-15T15:59:13.209161Z","iopub.status.idle":"2025-03-15T15:59:13.212755Z","shell.execute_reply.started":"2025-03-15T15:59:13.209139Z","shell.execute_reply":"2025-03-15T15:59:13.212000Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df=pd.DataFrame(x)","metadata":{"id":"etynR9dz4puy","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:15.734366Z","iopub.execute_input":"2025-03-15T15:59:15.734687Z","iopub.status.idle":"2025-03-15T15:59:15.765655Z","shell.execute_reply.started":"2025-03-15T15:59:15.734659Z","shell.execute_reply":"2025-03-15T15:59:15.764948Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df","metadata":{"id":"frGC33Ob4p2I","outputId":"77dc9a79-9e57-4e1f-cc41-08eca3982b3b","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:17.937022Z","iopub.execute_input":"2025-03-15T15:59:17.937296Z","iopub.status.idle":"2025-03-15T15:59:17.964282Z","shell.execute_reply.started":"2025-03-15T15:59:17.937275Z","shell.execute_reply":"2025-03-15T15:59:17.963480Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                 English  \\\n0                       cancel everything on my calendar   \n1      Adrenal hormone levels are at their peak durin...   \n2      Golden threads are obtained from Surat, the qu...   \n3              Look for agglutination within 30 seconds.   \n4      The non-pompousness and informality of their l...   \n...                                                  ...   \n80792  So, is it that this is the optimization proble...   \n80793  In this Masjid made with red stones there are ...   \n80794  He began to work on the movie on August 17, 20...   \n80795                          start a new shopping list   \n80796                 turn off the lights in the kitchen   \n\n                                                   Hindi  \n0                       मेरे कैलेंडर पर सब कुछ रद्द करें  \n1      अधिवृक्क के हार्मोन का स्तर प्रातःकाल में अपने...  \n2      स्वर्ण धागे सूरत से प्राप्त होते हैं, जिनकी गु...  \n3                  30 सेकेण्ड के भीतर एग्लूटिनेशन देखें।  \n4      उनके जीवन की आडंबरहीनता एवं अनौपचारिकता उनके स...  \n...                                                  ...  \n80792   तो, यह अनुकूलन समस्या है जिसमें हम रुचि रखते थे।  \n80793  लाल पत्थरों से बनायी गयी इस मस्जिद में हिन्दू ...  \n80794  उन्होंने 17 अगस्त, 2010 को फिल्म पर काम करना श...  \n80795                       एक नई खरीदारी सूची शुरू करें  \n80796                        रसोईघर की बत्तियाँ बंद करें  \n\n[80797 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Hindi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cancel everything on my calendar</td>\n      <td>मेरे कैलेंडर पर सब कुछ रद्द करें</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adrenal hormone levels are at their peak durin...</td>\n      <td>अधिवृक्क के हार्मोन का स्तर प्रातःकाल में अपने...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Golden threads are obtained from Surat, the qu...</td>\n      <td>स्वर्ण धागे सूरत से प्राप्त होते हैं, जिनकी गु...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Look for agglutination within 30 seconds.</td>\n      <td>30 सेकेण्ड के भीतर एग्लूटिनेशन देखें।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The non-pompousness and informality of their l...</td>\n      <td>उनके जीवन की आडंबरहीनता एवं अनौपचारिकता उनके स...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80792</th>\n      <td>So, is it that this is the optimization proble...</td>\n      <td>तो, यह अनुकूलन समस्या है जिसमें हम रुचि रखते थे।</td>\n    </tr>\n    <tr>\n      <th>80793</th>\n      <td>In this Masjid made with red stones there are ...</td>\n      <td>लाल पत्थरों से बनायी गयी इस मस्जिद में हिन्दू ...</td>\n    </tr>\n    <tr>\n      <th>80794</th>\n      <td>He began to work on the movie on August 17, 20...</td>\n      <td>उन्होंने 17 अगस्त, 2010 को फिल्म पर काम करना श...</td>\n    </tr>\n    <tr>\n      <th>80795</th>\n      <td>start a new shopping list</td>\n      <td>एक नई खरीदारी सूची शुरू करें</td>\n    </tr>\n    <tr>\n      <th>80796</th>\n      <td>turn off the lights in the kitchen</td>\n      <td>रसोईघर की बत्तियाँ बंद करें</td>\n    </tr>\n  </tbody>\n</table>\n<p>80797 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import nltk\nfrom collections import Counter","metadata":{"id":"3XRxnK3y4p6V","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:20.788354Z","iopub.execute_input":"2025-03-15T15:59:20.788727Z","iopub.status.idle":"2025-03-15T15:59:20.792348Z","shell.execute_reply.started":"2025-03-15T15:59:20.788670Z","shell.execute_reply":"2025-03-15T15:59:20.791607Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Function to preprocess and remove punctuation and numbers\ndef preprocess_and_remove_punctuation(sentence):\n    # Remove punctuation and numbers\n    sentence = ''.join([char for char in sentence if char not in string.punctuation and not char.isdigit()])\n    return sentence","metadata":{"id":"K9OBOZcH4p9Q","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:22.867215Z","iopub.execute_input":"2025-03-15T15:59:22.867535Z","iopub.status.idle":"2025-03-15T15:59:22.871379Z","shell.execute_reply.started":"2025-03-15T15:59:22.867508Z","shell.execute_reply":"2025-03-15T15:59:22.870622Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Tokenization and Lowercasing\ndef preprocess(sentences):\n    tokenized_sentences = [nltk.word_tokenize(preprocess_and_remove_punctuation(sentence.lower())) for sentence in sentences]\n    return tokenized_sentences","metadata":{"id":"TIZLuTIH4qCD","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:24.968804Z","iopub.execute_input":"2025-03-15T15:59:24.969204Z","iopub.status.idle":"2025-03-15T15:59:24.974224Z","shell.execute_reply.started":"2025-03-15T15:59:24.969170Z","shell.execute_reply":"2025-03-15T15:59:24.973181Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"target_sentences_train = [re.sub(r'[a-zA-Z]','',hi) for hi in target_sentences_train] #optional","metadata":{"id":"bKfE17bs4qI8","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:28.429458Z","iopub.execute_input":"2025-03-15T15:59:28.429782Z","iopub.status.idle":"2025-03-15T15:59:28.610616Z","shell.execute_reply.started":"2025-03-15T15:59:28.429752Z","shell.execute_reply":"2025-03-15T15:59:28.609738Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"english_tokens = preprocess(source_sentences_train)\nenglish_test=preprocess(source_sentences_val)\nhindi_tokens = preprocess(target_sentences_train)\nhindi_test=preprocess(target_sentences_val)","metadata":{"id":"Vlge8LLR4qKn","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:30.605411Z","iopub.execute_input":"2025-03-15T15:59:30.605680Z","iopub.status.idle":"2025-03-15T15:59:52.718869Z","shell.execute_reply.started":"2025-03-15T15:59:30.605659Z","shell.execute_reply":"2025-03-15T15:59:52.718060Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"en_train=english_tokens\nen_test=english_test\nde_train=hindi_tokens\nde_test=hindi_test","metadata":{"id":"deSMTBa-5maR","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:56.172930Z","iopub.execute_input":"2025-03-15T15:59:56.173313Z","iopub.status.idle":"2025-03-15T15:59:56.178074Z","shell.execute_reply.started":"2025-03-15T15:59:56.173283Z","shell.execute_reply":"2025-03-15T15:59:56.177170Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\nde_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n\nfor ds in [en_train, en_test]:\n    for sent in ds:\n        for token in sent:\n            if token not in en_index2word:\n                en_index2word.append(token)\n\nfor ds in [de_train, de_test]:\n    for sent in ds:\n        for token in sent:\n            if token not in de_index2word:\n                de_index2word.append(token)","metadata":{"id":"hhPcNh2L4qPT","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T15:59:59.357106Z","iopub.execute_input":"2025-03-15T15:59:59.357418Z","iopub.status.idle":"2025-03-15T16:03:32.643789Z","shell.execute_reply.started":"2025-03-15T15:59:59.357391Z","shell.execute_reply":"2025-03-15T16:03:32.642855Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"en_index2word","metadata":{"id":"vKBqf2kl9id2","outputId":"bd368e5c-f3e1-4cd8-b5c2-355cdc9e6042","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:03:37.036107Z","iopub.execute_input":"2025-03-15T16:03:37.036537Z","iopub.status.idle":"2025-03-15T16:03:37.058621Z","shell.execute_reply.started":"2025-03-15T16:03:37.036498Z","shell.execute_reply":"2025-03-15T16:03:37.057623Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['<PAD>',\n '<SOS>',\n '<EOS>',\n 'cancel',\n 'everything',\n 'on',\n 'my',\n 'calendar',\n 'adrenal',\n 'hormone',\n 'levels',\n 'are',\n 'at',\n 'their',\n 'peak',\n 'during',\n 'the',\n 'morning',\n 'and',\n 'taper',\n 'off',\n 'evening',\n 'reaching',\n 'a',\n 'low',\n 'level',\n 'around',\n 'am',\n 'an',\n 'important',\n 'function',\n 'of',\n 'these',\n 'hormones',\n 'is',\n 'to',\n 'regulate',\n 'vascular',\n 'muscle',\n 'tone',\n 'prevent',\n 'vasocodilation',\n 'golden',\n 'threads',\n 'obtained',\n 'from',\n 'surat',\n 'quality',\n 'being',\n 'yards',\n 'meters',\n 'per',\n 'tola',\n 'grams',\n 'look',\n 'for',\n 'agglutination',\n 'within',\n 'seconds',\n 'nonpompousness',\n 'informality',\n 'life',\n 'reflected',\n 'in',\n 'literature',\n 'also',\n 'world',\n 'chess',\n 'championship',\n 'which',\n 'kramnik',\n 'beat',\n 'fide',\n 'champion',\n 'veselin',\n 'topalov',\n 'reunified',\n 'titles',\n 'made',\n 'undisputed',\n 'heavily',\n 'embroidered',\n 'rugs',\n 'shawls',\n 'produced',\n 'gujarat',\n '’',\n 's',\n 'handloom',\n 'workshops',\n 'simply',\n 'beg',\n 'be',\n 'snuggled',\n 'into',\n 'so',\n 'therefore',\n 'we',\n 'need',\n 'way',\n 'variable',\n 'names',\n 'can',\n 'local',\n 'by',\n 'having',\n 'honey',\n 'mixed',\n 'onion',\n 'juice',\n 'lack',\n 'blood',\n 'body',\n 'removed',\n 'while',\n 'taking',\n 'bath',\n 'take',\n 'keeping',\n 'mouth',\n 'filled',\n 'with',\n 'water',\n 'drying',\n 'yourself',\n 'throw',\n 'out',\n 'due',\n 'this',\n 'one',\n 'will',\n 'never',\n 'get',\n 'cold',\n 'winters',\n 'give',\n 'me',\n 'updates',\n 'presidential',\n 'candidate',\n 'race',\n 'similarly',\n 'inscriptions',\n 'found',\n 'andhra',\n 'pradesh',\n 'karnataka',\n 'state',\n 'sanskrit',\n 'prakrit',\n 'now',\n 'fish',\n 'blind',\n 'birth',\n 'itself',\n 'show',\n 'all',\n 'scheduled',\n 'alarms',\n 'traditional',\n 'temples',\n 'india',\n 'not',\n 'run',\n 'like',\n 'isckon',\n 'green',\n 'tea',\n 'does',\n 'work',\n 'anti',\n 'aging',\n 'i',\n 'created',\n 'star',\n 'day',\n 'march',\n 'would',\n 'pass',\n 'through',\n 'districts',\n 'villages',\n 'was',\n 'first',\n 'country',\n 'national',\n 'program',\n 'blindness',\n 'prevention',\n 'started',\n 'after',\n 'detecting',\n 'comprehensiveness',\n 'deficiency',\n 'vitamin',\n 'weeds',\n 'should',\n 'allowed',\n 'stand',\n 'dawan',\n 'farms',\n 'weed',\n 'removing',\n 'done',\n 'least',\n 'times',\n 'farm',\n 'unless',\n 'carefully',\n 'managed',\n 'biomedical',\n 'waste',\n 'serious',\n 'pollutants',\n 'soil',\n 'air',\n 'few',\n 'years',\n 'ago',\n 'tv',\n 'did',\n 'sting',\n 'operations',\n 'about',\n 'casting',\n 'couch',\n 'industry',\n 'better',\n 'place',\n 'shopping',\n 'mall',\n 'road',\n 'coastal',\n 'region',\n 'famous',\n 'black',\n 'gram',\n 'paddy',\n 'stop',\n 'autopay',\n 'zomato',\n 'subscription',\n 'next',\n 'month',\n 'sleeping',\n 'ideal',\n 'only',\n 'time',\n 'but',\n 'avoid',\n 'disrupting',\n 'your',\n 'daily',\n 'routine',\n 'video',\n 'explain',\n 'what',\n 'problem',\n 'see',\n 'how',\n 'correct',\n 'it',\n 'write',\n 'right',\n 'programme',\n 'fizzbuzz',\n 'have',\n 'three',\n 'ts',\n 'course',\n 'heart',\n 'too',\n 'needs',\n 'fuel',\n 'its',\n 'if',\n 'you',\n 'sugar',\n 'then',\n 'regularly',\n 'pressure',\n 'check',\n 'up',\n 'ecg',\n 'urine',\n 'test',\n 'afterwards',\n 'attainment',\n 'missions',\n 'used',\n 'mass',\n 'education',\n 'propaganda',\n 'temple',\n 'has',\n 'small',\n 'trident',\n 'stone',\n 'statues',\n 'please',\n 'remove',\n 'alarm',\n 'set',\n 'wednesday',\n 'called',\n 'kickball',\n 'fear',\n 'reaction',\n 'subsided',\n 'minutes',\n 'end',\n 'raids',\n 'fruits',\n 'stored',\n 'before',\n 'ripening',\n 'essence',\n 'them',\n 'good',\n 'copenhagen',\n 'consensus',\n 'project',\n 'that',\n 'seeks',\n 'establish',\n 'priorities',\n 'advancing',\n 'global',\n 'welfare',\n 'using',\n 'methodologies',\n 'based',\n 'theory',\n 'economics',\n 'smt',\n 'sharan',\n 'rani',\n 'woman',\n 'who',\n 'expertise',\n 'difficult',\n 'instrument',\n 'sarod',\n 'crown',\n 'cave',\n 'guanyan',\n 'crownlike',\n 'crag',\n 'earns',\n 'hill',\n 'name',\n 'mu',\n 'x',\n 'between',\n 'further',\n 'epidemics',\n 'occurred',\n 'french',\n 'polynesia',\n 'easter',\n 'island',\n 'cook',\n 'islands',\n 'new',\n 'caledonia',\n 'people',\n 'iq',\n 'less',\n 'than',\n 'considered',\n 'extremely',\n 'mixing',\n 'lemon',\n 'orange',\n 'grape',\n 'oily',\n 'skin',\n 'essential',\n 'oil',\n 'apply',\n 'dots',\n 'dont',\n 'exceed',\n 'cm',\n 'diameter',\n 'encourage',\n 'higher',\n 'studies',\n 'specialization',\n 'nursing',\n 'subjects',\n 'scholarships',\n 'awarded',\n 'students',\n 'amusement',\n 'parks',\n 'animal',\n 'indoor',\n 'outdoor',\n 'playgrounds',\n 'petting',\n 'zoos',\n 'casinos',\n 'gambling',\n 'offices',\n 'leisure',\n 'centres',\n 'closed',\n 'until',\n 'may',\n 'included',\n 'such',\n 'illness',\n 'controlled',\n 'scabies',\n 'more',\n 'common',\n 'children',\n 'women',\n 'appears',\n 'widespread',\n 'north',\n 'england',\n 'full',\n 'coverage',\n 'arms',\n 'front',\n 'neck',\n 'midthigh',\n 'or',\n 'below',\n 'ensures',\n 'clothing',\n 'exposed',\n 'upper',\n 'areas',\n 'protected',\n 'chamba',\n 'ancient',\n 'capital',\n 'pahari',\n 'kings',\n 'situated',\n 'bank',\n 'river',\n 'ravi',\n 'altitude',\n 'general',\n 'health',\n 'workers',\n 'concerned',\n 'when',\n 'crude',\n 'mortality',\n 'rates',\n 'cmrs',\n 'displaced',\n 'population',\n 'underfive',\n 'carer',\n 'visits',\n 'home',\n 'they',\n 'wear',\n 'protective',\n 'equipment',\n 'reduce',\n 'risk',\n 'catching',\n 'infection',\n 'ever',\n 'email',\n 'sean',\n 'today',\n 'rifle',\n 'association',\n 'nrai',\n 'founded',\n 'view',\n 'promoting',\n 'popularising',\n 'shooting',\n 'sports',\n 'visakapattinam',\n 'city',\n 'biggest',\n 'harbors',\n 'carrying',\n 'large',\n 'exports',\n 'imports',\n 'rises',\n 'form',\n 'mat',\n 'talk',\n 'mom',\n 'say',\n 'belongs',\n 'rn',\n 'narrowing',\n 'vessels',\n 'she',\n 'continue',\n 'getting',\n 'dose',\n 'every',\n 'six',\n 'hemp',\n 'liberate',\n 'patient',\n 'unbearable',\n 'pain',\n 'occuring',\n 'operation',\n 'guwahati',\n 'commercial',\n 'northeastern',\n 'states',\n 'assam',\n 'wrong',\n 'media',\n 'greater',\n 'emphasis',\n 'financial',\n 'concerns',\n 'thereby',\n 'causing',\n 'stress',\n 'th',\n 'century',\n 'exported',\n 'eastwards',\n 'influenced',\n 'genesis',\n 'almost',\n 'southeast',\n 'asian',\n 'scripts',\n 'do',\n 'documents',\n 'relating',\n 'temporary',\n 'unemployment',\n 'still',\n 'stamped',\n 'municipality',\n 'some',\n 'types',\n 'thrift',\n 'shops',\n 'looking',\n 'kind',\n 'worn',\n 'dated',\n 'canada',\n 'dallas',\n 'proofreader',\n 'mechanical',\n 'inaccuracies',\n 'basis',\n 'self',\n 'decision',\n 'busy',\n 'weekend',\n 'interpret',\n 'uncertainty',\n 'as',\n 'open',\n 'invitation',\n 'sell',\n 'something',\n 'describe',\n 'product',\n 'there',\n 'many',\n 'ways',\n 'maintaining',\n 'beauty',\n 'just',\n 'make',\n 'effort',\n 'year',\n 'came',\n 'her',\n 'shock',\n 'husband',\n 'died',\n 'unexpectedly',\n 'market',\n 'coriander',\n 'contains',\n 'lot',\n 'external',\n 'elements',\n 'stems',\n 'dust',\n 'fenugreek',\n 'guest',\n 'house',\n 'cooking',\n 'own',\n 'food',\n 'both',\n 'facilities',\n 'available',\n 'consisting',\n 'twin',\n 'cities',\n 'hyderabad',\n 'secunderabad',\n 'pulse',\n 'polio',\n 'mission',\n 'safety',\n 'child',\n 'under',\n 'family',\n 'department',\n 'indian',\n 'government',\n 'order',\n 'keep',\n 'free',\n 'medicine',\n 'drink',\n 'cost',\n 'play',\n 'transistor',\n 'tape',\n 'radio',\n 'etc',\n 'loudly',\n 'obstruct',\n 'path',\n 'coming',\n 'going',\n 'travellers',\n 'store',\n 'other',\n 'well',\n 'ibuprofen',\n 'two',\n 'were',\n 'divine',\n 'incidents',\n 'because',\n 'no',\n 'results',\n 'exploration',\n 'visible',\n 'feels',\n 'burning',\n 'clearly',\n 'communicate',\n 'emotions',\n 'partner',\n 'sentence',\n 'composition',\n 'fronting',\n 'backing',\n 'paragraph',\n 'seen',\n 'proof',\n 'reader',\n 'dishes',\n 'exclusive',\n 'punjab',\n 'including',\n 'sarson',\n 'da',\n 'saag',\n 'tandoori',\n 'chicken',\n 'shami',\n 'kebab',\n 'makki',\n 'di',\n 'roti',\n 'awadhi',\n 'cuisine',\n 'replete',\n 'various',\n 'varieties',\n 'kebabs',\n 'tunde',\n 'ke',\n 'arguable',\n 'most',\n 'delicious',\n 'his',\n 'father',\n 'married',\n 'nur',\n 'jahan',\n 'widowed',\n 'daughter',\n 'persian',\n 'noble',\n 'wash',\n 'hair',\n 'lukewarm',\n 'reign',\n 'maharaja',\n 'savai',\n 'maansingh',\n 'ii',\n 'got',\n 'arches',\n 'main',\n 'doors',\n 'boundary',\n 'garden',\n 'wherefrom',\n 'cool',\n 'breeze',\n 'keeps',\n 'continuously',\n 'occupying',\n 'parts',\n 'administrative',\n 'jago',\n 'de',\n 'la',\n 'vega',\n 'cause',\n 'tuberculosis',\n 'negligence',\n 'nutritional',\n 'medicinal',\n 'point',\n 'jaggery',\n 'want',\n 'hear',\n 'rap',\n 'dark',\n 'returned',\n 'mostly',\n 'core',\n 'topics',\n 'plumber',\n 'tell',\n 'repair',\n 'complex',\n 'pricey',\n 'research',\n 'led',\n 'expect',\n 'popularity',\n 'present',\n 'innumerable',\n 'jokes',\n 'parodies',\n 'lines',\n 'comedians',\n 'any',\n 'appointments',\n 'summers',\n 'arunachal',\n 'carpet',\n 'colorful',\n 'flowers',\n 'gets',\n 'spread',\n 'lakes',\n 'become',\n 'field',\n 'snow',\n 'been',\n 'frozen',\n 'favorite',\n 'hotels',\n 'gurgaon',\n 'spatial',\n 'designer',\n 'luxury',\n 'pataudi',\n 'palace',\n 'where',\n 'enter',\n 'quite',\n 'another',\n 'proper',\n 'treatment',\n 'sexually',\n 'infected',\n 'diseases',\n 'complexities',\n 'arise',\n 'miami',\n 'heat',\n 'warriors',\n 'game',\n 'pushing',\n 'players',\n 'without',\n 'ball',\n 'competing',\n 'loose',\n 'disallowed',\n 'infractions',\n 'lead',\n 'twominute',\n 'penalties',\n 'notice',\n 'find',\n 'slight',\n 'change',\n 'prompt',\n 'ghci',\n 'gives',\n 'modern',\n 'designs',\n 'sail',\n 'mainsail',\n 'however',\n 'catboat',\n 'could',\n 'carry',\n 'multiple',\n 'sails',\n 'gaff',\n 'rig',\n 'train',\n 'noncompetitive',\n 'environment',\n 'minimized',\n 'subcontinent',\n 'peanuts',\n 'known',\n 'light',\n 'snack',\n 'themselves',\n 'usually',\n 'roasted',\n 'salted',\n 'sometimes',\n 'addition',\n 'chilli',\n 'powder',\n 'often',\n 'sold',\n 'pod',\n 'boiled',\n 'salt',\n 'relief',\n 'excreting',\n 'music',\n 'inquisitive',\n 'aware',\n 'sangeet',\n 'ratnakar',\n 'immortal',\n 'creation',\n 'pandit',\n 'shangardev',\n 'membership',\n 'costco',\n 'shop',\n 'signed',\n 'member',\n 'process',\n 'internal',\n 'glands',\n 'takes',\n 'according',\n 'rules',\n 'surya',\n 'namaskara',\n 'following',\n 'cut',\n 'puncture',\n 'post',\n 'exposure',\n 'prophylaxis',\n 'hiv',\n 'contemplated',\n 'use',\n 'schedule',\n 'coffee',\n 'preferably',\n 'hot',\n 'hotel',\n 'taj',\n 'residency',\n 'rama',\n 'international',\n 'inn',\n 'vedant',\n 'popular',\n 'juicy',\n 'spoiled',\n 'easily',\n 'along',\n 'packing',\n 'necessary',\n 'ascertain',\n 'timely',\n 'arrangement',\n 'transport',\n 'list',\n 'had',\n 'taken',\n 'developing',\n 'park',\n 'soaps',\n 'come',\n 'especially',\n 'either',\n 'period',\n 'everyone',\n 'talking',\n 'deep',\n 'learning',\n 'company',\n 'investing',\n 'lantern',\n 'displays',\n 'processions',\n 'held',\n 'conjunction',\n 'moon',\n 'cake',\n 'festival',\n 'commemorate',\n 'honor',\n 'support',\n 'thimpu',\n 'chu',\n 'south',\n 'direction',\n 'middle',\n 'docin',\n 'choling',\n 'simtokha',\n 'ramleela',\n 'earned',\n 'rupees',\n 'crores',\n 'theatrical',\n 'emerged',\n 'fifth',\n 'highestgrossing',\n 'film',\n 'films',\n 'putlikhoh',\n 'waterfall',\n 'reach',\n 'born',\n 'innate',\n 'physical',\n 'defects',\n 'organfractures',\n 'limb',\n 'disorder',\n 'inner',\n 'surface',\n 'mould',\n 'mud',\n 'mica',\n 'coal',\n 'dry',\n 'grass',\n 'moulds',\n 'very',\n 'strong',\n 'rainy',\n 'event',\n 'attracts',\n 'hundreds',\n 'tourists',\n 'pockets',\n 'different',\n 'colour',\n 'mood',\n 'trying',\n 'hands',\n 'muchloved',\n 'sport',\n 'schools',\n 'private',\n 'trusts',\n 'sorry',\n 'loop',\n 'care',\n 'why',\n 'wrote',\n 'meghahatuburu',\n 'forest',\n 'village',\n 'average',\n 'literacy',\n 'rate',\n 'male',\n 'female',\n 'epd',\n 'tried',\n 'autoimmune',\n 'again',\n 'fda',\n 'approved',\n ...]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Save vocabularies for English-Hindi\nwith open('/kaggle/working/hi_en_index2word.json', 'w') as f:\n    json.dump(en_index2word, f)\nwith open('/kaggle/working/hi_de_index2word.json', 'w') as f:\n    json.dump(de_index2word, f)\nprint(\"English-Hindi vocabularies saved to /content/hi_en_index2word.json and /content/hi_de_index2word.json\")\n\n# Save vocabularies for English-Bengali\n#with open('/content/en_index2word_bn.json', 'w') as f:\n#    json.dump(en_index2word_bn, f)\n#with open('/content/bn_index2word.json', 'w') as f:\n#    json.dump(bn_index2word, f)\n#print(\"English-Bengali vocabularies saved to /content/en_index2word_bn.json and /content/bn_index2word.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:03:46.465299Z","iopub.execute_input":"2025-03-15T16:03:46.465591Z","iopub.status.idle":"2025-03-15T16:03:46.534161Z","shell.execute_reply.started":"2025-03-15T16:03:46.465570Z","shell.execute_reply":"2025-03-15T16:03:46.533538Z"}},"outputs":[{"name":"stdout","text":"English-Hindi vocabularies saved to /content/hi_en_index2word.json and /content/hi_de_index2word.json\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# torch.cuda.is_available() checks if a CUDA-enabled GPU is available.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"op5h3x5a7lKz","outputId":"3455f8af-d6dc-46bc-b6a0-d5274ddf8e9d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# It iterates through the en_index2word list using enumerate(), which provides both the index (idx) and the value (token, which is a word).\n# For each word, it creates a key-value pair in the dictionary, where the key is the word (token) and the value is its index (idx).\nen_word2index = {token: idx for idx, token in enumerate(en_index2word)}\nde_word2index = {token: idx for idx, token in enumerate(de_index2word)}","metadata":{"id":"YCD8R66I7lMs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(en_word2index)","metadata":{"id":"3NAVQ4Wc4qTd","outputId":"7a1936eb-4b00-49e9-e1a2-03076dade37e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#it divides the total length by the number of sentences (len(en_train)) to get the average sentence length.\nen_lengths = sum([len(sent) for sent in en_train])/len(en_train)\nde_lengths = sum([len(sent) for sent in de_train])/len(de_train)","metadata":{"id":"VhU217lr4njs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_length = 20","metadata":{"id":"bUmeVoIn61Kx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_and_pad(vocab, sent, max_length):\n    \"\"\"\n    Encodes a sentence using a vocabulary and pads or truncates it to a specified maximum length.\n\n    Args:\n        vocab (dict): A dictionary mapping words to their corresponding indices.\n        sent (list): A list of words representing the sentence to be encoded.\n        max_length (int): The maximum length of the encoded and padded/truncated sentence.\n\n    Returns:\n        list: The encoded and padded/truncated sentence as a list of indices.\n    \"\"\"\n\n    # Define special tokens: Start of Sentence (SOS), End of Sentence (EOS), and Padding (PAD).\n    sos = [vocab[\"<SOS>\"]]\n    eos = [vocab[\"<EOS>\"]]\n    pad = [vocab[\"<PAD>\"]]\n\n    # Check if the sentence length (excluding SOS and EOS) is less than the maximum length.\n    if len(sent) < max_length - 2: # -2 for SOS and EOS\n        # Calculate the number of padding tokens needed.\n        n_pads = max_length - 2 - len(sent)\n        # Encode the sentence by looking up the index of each word in the vocabulary.\n        encoded = [vocab[w] for w in sent]\n        return sos + encoded + eos + pad * n_pads\n    else: # sent is longer than max_length; truncating\n        encoded = [vocab[w] for w in sent]\n        truncated = encoded[:max_length - 2]\n        return sos + truncated + eos","metadata":{"id":"hKpPwrsb61Of","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encoded Training data\nen_train_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_train]\nen_test_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_test]\nde_train_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_train]\nde_test_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_test]","metadata":{"id":"zOVE8NxB61SJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"en_train_encoded[1]","metadata":{"id":"HQeTtXSK-G3p","outputId":"449aa297-94b7-4e08-cee2-edbd0fffc6e3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 256\n\ntrain_x = np.array(en_train_encoded)\ntrain_y = np.array(de_train_encoded)\ntest_x = np.array(en_test_encoded)\ntest_y = np.array(de_test_encoded)\n\ntrain_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\ntest_ds = TensorDataset(torch.from_numpy(test_x))\n\n\n#train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\ntrain_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=2) #added pin_memory and num_workers\n#test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)","metadata":{"id":"zIC407YH9Eif","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_x[1]","metadata":{"id":"zWzPn5U3-iX2","outputId":"59e4264a-cf3e-4aca-872e-a668fff665f4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds[1]","metadata":{"id":"IpdQcKeB-siQ","outputId":"bf3af5a6-6f3e-4eb1-d861-25f254460d42","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math","metadata":{"id":"IxcBu2_S8HsY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"Ayb64QDK91uR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# As suggested in online docs we need to use a positional encoder for Transformaers\n\nclass PositionalEncoding(nn.Module):\n    \"\"\"\n    This module implements positional encoding for transformer models.\n    Written with help of:\n    https://www.geeksforgeeks.org/positional-encoding-in-transformers/\n    https://github.com/hyunwoongko/transformer\n\n    Positional encoding adds information about the position of tokens in a sequence to the input embeddings.\n    This is crucial because transformer models, unlike recurrent neural networks, do not inherently\n    process sequential data in order.\n    \"\"\"\n    def __init__(self, d_model, max_len=5000):\n        \"\"\"\n        Initializes the PositionalEncoding module.\n\n        Args:\n            d_model (int): The dimensionality of the input embeddings.\n            max_len (int): The maximum length of the sequences the model can handle.\n        \"\"\"\n        # Create a zero tensor of shape (max_len, d_model) to store the positional encodings.\n        super(PositionalEncoding, self).__init__()\n        # Create a zero tensor of shape (max_len, d_model) to store the positional encodings.\n        pe = torch.zeros(max_len, d_model)\n        # Create a tensor of positions from 0 to max_len-1.\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        # Calculate the division term for the sinusoidal functions.\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        # Calculate the sine and cosine values for even indices and odd indices.\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        # Add a batch dimension to the positional encoding tensor. WHY????? TODO figure out\n        pe = pe.unsqueeze(0)\n        # Buffers are tensors that  are not updated during trainin but are still\n        # saved in the model's state dictionary.\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        Applies positional encoding to the input tensor.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, sequence_length, d_model).\n\n        Returns:\n            torch.Tensor: The input tensor with positional encoding added, of the same shape as x.\n        \"\"\"\n        # The positional encoding is sliced to match the sequence length of the input.\n        return x + self.pe[:, :x.size(1), :]\n","metadata":{"id":"nrjcbW8T4JEY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Improved Encoder and Decoder with LSTM and Attention\nclass EnhancedEncoder(nn.Module):\n    \"\"\"\n    An enhanced encoder module that combines embedding, positional encoding, multi-head attention,\n    and feed-forward network for sequence encoding.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_heads=4, dropout=0.1):\n        \"\"\"\n        Initializes the EnhancedEncoder module.\n\n        Args:\n            input_size (int): The size of the input vocabulary.\n            hidden_size (int): The dimensionality of the hidden state and embeddings.\n            num_heads (int): The number of attention heads.\n            dropout (float): Dropout probability.\n        \"\"\"\n        super(EnhancedEncoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n\n        # Embedding layer to convert input tokens to embeddings.\n        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n        # Positional encoding to add positional information to embeddings.\n        self.pos_encoding = PositionalEncoding(hidden_size)\n        # Multi-head attention layer.\n        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Layer normalization after attention.\n        self.norm1 = nn.LayerNorm(hidden_size)\n        # Layer normalization after feed-forward network.\n        self.norm2 = nn.LayerNorm(hidden_size)\n        # Feed-forward network.\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size * 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size * 4, hidden_size)\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, hidden=None):\n        \"\"\"\n        Forward pass of the encoder.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (batch_size, seq_length).\n            hidden (torch.Tensor, optional): Hidden state (not used in this encoder).\n\n        Returns:\n            tuple: A tuple containing the encoder output and None (for compatibility).\n        \"\"\"\n        # Embed the input tokens. \n        embedded = self.embedding(input)  # [batch_size, seq_length, hidden_size]\n        # Add positional encoding. need to figure out why this is a must\n        embedded = self.pos_encoding(embedded)\n        # Permute dimensions for multi-head attention. \n        # https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853\n        embedded = embedded.permute(1, 0, 2)  # [seq_length, batch_size, hidden_size]\n\n        # Apply multi-head attention.\n        # https://paperswithcode.com/method/multi-head-attention\n        attn_output, _ = self.attention(embedded, embedded, embedded)\n        attn_output = self.norm1(embedded + self.dropout(attn_output))\n        ffn_output = self.ffn(attn_output)\n        output = self.norm2(attn_output + self.dropout(ffn_output))\n        output = output.permute(1, 0, 2)  # [batch_size, seq_length, hidden_size]\n        return output, None\n\n    def initHidden(self):\n        \"\"\"\n        Initializes the hidden state (not used in this encoder).\n\n        Returns:\n            None\n        \"\"\"\n        return None","metadata":{"id":"1hNA9u659U-E","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EnhancedDecoder(nn.Module):\n    \"\"\"\n    An enhanced decoder module that combines embedding, positional encoding, self-attention,\n    encoder-decoder attention, and a feed-forward network for sequence decoding.\n    \"\"\"\n    def __init__(self, hidden_size, output_size, num_heads=4, dropout=0.1):\n        \"\"\"\n        Initializes the EnhancedDecoder module.\n\n        Args:\n            hidden_size (int): The dimensionality of the hidden state and embeddings.\n            output_size (int): The size of the output vocabulary.\n            num_heads (int): The number of attention heads.\n            dropout (float): Dropout probability.\n        \"\"\"\n        super(EnhancedDecoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n\n        # Embedding layer to convert input tokens to embeddings.\n        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n        # Positional encoding to add positional information to embeddings.\n        self.pos_encoding = PositionalEncoding(hidden_size)\n        # Self-attention layer.\n        self.self_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Encoder-decoder attention layer.\n        self.enc_dec_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n        # Layer normalization after self-attention.\n        self.norm1 = nn.LayerNorm(hidden_size)\n        # Layer normalization after encoder-decoder attention.\n        self.norm2 = nn.LayerNorm(hidden_size)\n        # Layer normalization after feed-forward network.\n        self.norm3 = nn.LayerNorm(hidden_size)\n        # Feed-forward network.\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size * 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size * 4, hidden_size)\n        )\n        # Output linear layer.\n        self.out = nn.Linear(hidden_size, output_size)\n        # Log softmax for output probabilities.\n        self.softmax = nn.LogSoftmax(dim=-1)\n        # Dropout layer.\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, encoder_output, mask=None):\n        \"\"\"\n        Forward pass of the decoder.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n            encoder_output (torch.Tensor): Output tensor from the encoder of shape (batch_size, src_seq_len, hidden_size).\n            mask (torch.Tensor, optional): Mask for self-attention (e.g., for padding or look-ahead).\n\n        Returns:\n            tuple: A tuple containing the decoder output and None (for compatibility).\n        \"\"\"\n        # Embed the input tokens.\n        embedded = self.embedding(input)  # [batch_size, seq_len, hidden_size]\n        # Add positional encoding.\n        embedded = self.pos_encoding(embedded)\n        # Permute dimensions for multi-head attention.\n        embedded = embedded.permute(1, 0, 2)  # [seq_len, batch_size, hidden_size]\n        # Permute encoder output dimensions for encoder-decoder attention.\n        enc_output = encoder_output.permute(1, 0, 2)  # [src_seq_len, batch_size, hidden_size]\n\n        # Apply self-attention.\n        self_attn_output, _ = self.self_attention(embedded, embedded, embedded, attn_mask=mask)\n        # Apply layer normalization and residual connection after self-attention.\n        self_attn_output = self.norm1(embedded + self.dropout(self_attn_output))\n\n        # Apply encoder-decoder attention.\n        attn_output, _ = self.enc_dec_attention(self_attn_output, enc_output, enc_output)\n        # Apply layer normalization and residual connection after encoder-decoder attention.\n        attn_output = self.norm2(self_attn_output + self.dropout(attn_output))\n\n        # Apply feed-forward network.\n        ffn_output = self.ffn(attn_output)\n        # Apply layer normalization and residual connection after feed-forward network.\n        output = self.norm3(attn_output + self.dropout(ffn_output))\n        # Permute dimensions back to (batch_size, seq_len, hidden_size).\n        output = output.permute(1, 0, 2)  # [batch_size, seq_len, hidden_size]\n\n        # Output logits for the last token only\n        output = self.out(output[:, -1, :])  # [batch_size, output_size]\n        output = self.softmax(output)\n        return output, None\n\n    # We do not need an .initHidden() method for the decoder since the encoder output will act as input in the first decoder time-step","metadata":{"id":"d050fwM09Xad","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modified instantiation\nhidden_size = 128  # Increased hidden size for better representation\nencoder = EnhancedEncoder(len(en_index2word), hidden_size).to(device)\ndecoder = EnhancedDecoder(hidden_size, len(de_index2word)).to(device)\n\n#criterion = nn.CrossEntropyLoss(ignore_index=0)\n#enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n#dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n\n# Training loop\ncriterion = nn.CrossEntropyLoss()\nenc_optimizer = torch.optim.Adam(encoder.parameters(), lr=3e-3)\ndec_optimizer = torch.optim.Adam(decoder.parameters(), lr=3e-3)\n\nlosses = []\n\n\n#EPOCHS\n\n\n\nepochs = 50  # Increased epochs since transformer-style models often need more training\nSOS = en_word2index[\"<SOS>\"]\nEOS = en_word2index[\"<EOS>\"]","metadata":{"id":"9KKwV9qS9Eyw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    \"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf')\"\"\"\n    # Create an upper triangular matrix of ones.\n    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n    # Replace 0s with float('-inf') and 1s with 0.0.\n    # masked_fill(condition, value) replaces elements where the condition is true with the specified value.\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask","metadata":{"id":"5IH25tA04lYz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_epoch(encoder, decoder, train_dl, criterion, enc_optimizer, dec_optimizer):\n    \"\"\"\n    Trains the encoder and decoder models for one epoch.\n\n    Args:\n        encoder (nn.Module): The encoder model.\n        decoder (nn.Module): The decoder model.\n        train_dl (DataLoader): DataLoader for the training dataset.\n        criterion (nn.Module): Loss function.\n        enc_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n        dec_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n\n    Returns:\n        float: Average loss for the epoch.\n    \"\"\"\n    # Set the models to training mode.\n    encoder.train()\n    decoder.train()\n    total_loss = 0\n\n    # Iterate over batches in the training DataLoader.\n    for idx, batch in enumerate(train_dl):\n        # Move input and target tensors to the device.\n        input_tensor = batch[0].to(device)  # [batch_size, seq_length]\n        target_tensor = batch[1].to(device)  # [batch_size, seq_length]\n\n        # Zero the gradients of the optimizers.\n        enc_optimizer.zero_grad()\n        dec_optimizer.zero_grad()\n\n        # Enable gradient calculation.\n        with torch.set_grad_enabled(True):\n            # Encode the input sequence.\n            encoder_output, _ = encoder(input_tensor)\n\n            # Initialize decoder input with SOS token.\n            batch_size = input_tensor.size(0)\n            decoder_input = torch.full((batch_size, 1), SOS, dtype=torch.long).to(device)\n            # Generate the mask for the decoder.\n            mask = generate_square_subsequent_mask(seq_length).to(device)\n            # Initialize a tensor to store the decoder results.\n            dec_result = torch.zeros(batch_size, seq_length, len(de_index2word)).to(device)\n\n            # Iterate over the target sequence length.\n            for t in range(1, seq_length):\n                # Decode the input sequence up to time step t\n                decoder_output, _ = decoder(\n                    decoder_input[:, :t],\n                    encoder_output,\n                    mask[:t, :t]\n                )\n                # Assign the 2D output directly\n                dec_result[:, t] = decoder_output  # [batch_size, vocab_size]\n\n                # Prepare the next decoder input.\n                if t < seq_length - 1:\n                    decoder_input = torch.cat(\n                        [decoder_input, target_tensor[:, t].unsqueeze(1)],\n                        dim=1\n                    )\n\n            # Reshape the decoder results and target tensor for loss calculation.\n            scores = dec_result[:, 1:].reshape(-1, len(de_index2word))\n            targets = target_tensor[:, 1:].reshape(-1)\n            loss = criterion(scores, targets)\n\n            # Backpropagate the loss and update the model parameters.\n            loss.backward()\n            # Clip gradients to prevent exploding gradients. Smoothing the learning process\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n            enc_optimizer.step()\n            dec_optimizer.step()\n\n            total_loss += loss.item()\n\n            if idx % 10 == 0:\n                avg_loss = total_loss / (idx + 1)\n                print(f\"Batch {idx}, Loss: {avg_loss:.4f}\")\n\n    # Average loss for this epoch\n    return total_loss / len(train_dl)","metadata":{"id":"PaZA3ZXr-YNL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full training loop\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n    avg_loss = train_epoch(encoder, decoder, train_dl, criterion, enc_optimizer, dec_optimizer)\n    losses.append(avg_loss)\n    print(f\"Average Loss: {avg_loss:.4f}\")","metadata":{"id":"KlQHK9zb468x","outputId":"52f752f8-f399-4ec3-b7c8-357f24093d14","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot losses\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Over Time')\nplt.show()","metadata":{"id":"xuyYw5C29E6Q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save models for English-Hindi\ntorch.save(encoder.state_dict(), '/kaggle/working/encoder_hi.pth')\ntorch.save(decoder.state_dict(), '/kaggle/working/decoder_hi.pth')\nprint(\"English-Hindi Encoder and Decoder saved\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modified evaluation code\n# Evaluation\n# Corrected Evaluation\ndef evaluate(encoder, decoder, test_ds):\n    \"\"\"\n    Evaluates the encoder and decoder models on the test dataset.\n\n    Args:\n        encoder (nn.Module): The encoder model.\n        decoder (nn.Module): The decoder model.\n        test_ds (Dataset): The test dataset.\n\n    Returns:\n        list: A list of predicted sentences as strings.\n    \"\"\"\n    # Set the models to evaluation mode.\n    encoder.eval()\n    decoder.eval()\n    val_outs = []\n\n    # Disable gradient calculation during evaluation.\n    with torch.no_grad():\n        # Iterate over the test dataset.\n        for i in tqdm(range(len(test_ds))):\n            # Get the input tensor and move it to the device.\n            input_tensor = test_ds[i][0].unsqueeze(0).to(device)\n            encoder_output, _ = encoder(input_tensor)\n            # Initialize the decoder input with the SOS token.\n            decoder_input = torch.tensor([[SOS]], device=device)  # [1, 1]\n            result = []\n\n            # Iterate over the sequence length.\n            for t in range(seq_length):\n                # Generate the mask for the decoder.\n                mask = generate_square_subsequent_mask(t + 1).to(device)\n                # Decode the input sequence up to time step t.\n                decoder_output, _ = decoder(decoder_input, encoder_output, mask)\n                # Get the predicted token index.\n                best = decoder_output.argmax(-1)  # [batch_size], here [1]\n                pred_token = best.item()\n                \n                result.append(de_index2word[pred_token])\n\n                # Check if the predicted token is the EOS token.\n                if pred_token == EOS:\n                    break\n                    \n                \n                # Prepare the next decoder input.\n                # Ensure 2D tensor by concatenating with a tensor containing the pred_token.\n                # Fix: by unsqueezing only once\n                decoder_input = torch.cat(\n                    [decoder_input, torch.tensor([[pred_token]], device=device)],\n                    dim=1\n                )\n\n            # Remove special tokens from the result list.\n            result = [token for token in result if token not in ['<EOS>', '<PAD>', '<SOS>']]\n            # Construct sentence\n            val_outs.append(\" \".join(result))\n    \n    return val_outs","metadata":{"id":"pZBPRQqM5Pfz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nencoder = EnhancedEncoder(len(en_index2word), hidden_size).to(device)\ndecoder = EnhancedDecoder(hidden_size, len(de_index2word)).to(device)\n\n\n#encoder.load_state_dict(torch.load('/kaggle/working/encoder_hi.pth'))\n#decoder.load_state_dict(torch.load('/kaggle/working/decoder_hi.pth'))\n\n# Load saved state dictionaries with weights_only=True\nencoder.load_state_dict(torch.load('/kaggle/working/encoder_hi.pth', weights_only=True))\ndecoder.load_state_dict(torch.load('/kaggle/working/decoder_hi.pth', weights_only=True))\nprint(\"English-Hindi Encoder and Decoder loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run evaluation\nval_ids = [i for i, _ in data[\"English-Hindi\"][\"Validation\"].items()]\nval_outs = evaluate(encoder, decoder, test_ds)","metadata":{"id":"keeFGS8L5RgB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save results\ndf0 = pd.DataFrame()\ndf0[\"ID\"] = val_ids\ndf0[\"Translation\"] = val_outs\ndf0.to_csv('/kaggle/working/answersH.csv', index=False)\n#df0.to_csv('/kaggle/working/answersB.csv', index=False)","metadata":{"id":"83naaUJdGthF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=pd.read_csv(\"/kaggle/working/answersH.csv\")","metadata":{"id":"0YPeBfJDGtmL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x","metadata":{"id":"A2S8UnGoLKDt","trusted":true},"outputs":[],"execution_count":null}]}